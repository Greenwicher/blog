<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Greenwicher&#39;s Blog</title>
  <meta name="author" content="LIU Weizhi">
  
  <meta name="description" content="努力成为人工智能、算法与数据结构、量化交易这三大领域的价值博客">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Greenwicher&#39;s Blog"/>

  
    <meta property="og:image" content="undefined"/>
  

  
    <link rel="alternative" href="/atom.xml" title="Greenwicher&#39;s Blog" type="application/atom+xml">
  
  
    <link href="/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/css/themes/bootstrap.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>
  <script src="/js/bootstrap.min.js"></script>
  <!-- analytics -->
  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-42890116-1', 'auto');
  ga('send', 'pageview');
</script>




</head>

 <body>  
  <nav id="main-nav" class="navbar navbar-inverse navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="http://greenwicher.com">Greenwicher&#39;s Blog</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href= "/" title="Blog homepage"> 
			  <i class="fa fa-home"></i>首页
			</a>
		  </li>
		  
		  <li>
			<a href= "/archives" title="All the articles."> 
			  <i class="fa fa-archive"></i>归档
			</a>
		  </li>
		  
		  <li>
			<a href= "/categories" title="All the categories."> 
			  <i class="fa fa-folder"></i>分类
			</a>
		  </li>
		  
		  <li>
			<a href= "/tags" title="All the tags."> 
			  <i class="fa fa-tags"></i>标签
			</a>
		  </li>
		  
		  <li>
			<a href= "/subscribe" title="Subscribe"> 
			  <i class="fa fa-rss"></i>订阅
			</a>
		  </li>
		  
		  <li>
			<a href= "https://book.douban.com/people/Greenwicher/" title="Douban"> 
			  <i class="fa fa-book"></i>读书
			</a>			
	          </li>
		  <li>
			<a href= "http://greenwicher.com/me/cv.pdf" title="Me"> 
			  <i class="fa fa-user"></i>关于我
			</a>			
	          </li>
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 <div class="page-header page-header-inverse ">
  <h1 class="title title-inverse ">Blog</h1>
</div>

<div class="row page">

	
	<div class="col-md-9">
	

		<div class="slogan">
      <i class="fa fa-heart"></i>
      人工智能|量化交易|算法与数据结构
</div>    
		<div id="top_search"></div>
		<div class="mypage">
		
		<!-- title and entry -->
		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> Jan 9 2017 </div>
			<div class="article-title"><a href="/2017/01/09/drl-general_ai-intro-test/" title="邮件订阅测试">邮件订阅测试</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
           
  	      <div class="thumbnail"><a href="/2017/01/09/drl-general_ai-intro-test/"><img src="/2017/01/09/drl-general_ai-intro-test/http://blog.greenwicher.com/2016/12/18/drl-general_ai-intro/DQNBreaker_Atari.jpg" alt="邮件订阅测试"  class="nofancybox"></a>
           
		</div>
	
        
		<p>现在但凡写人工智能的文章，必提<a href="https://deepmind.com/research/alphago/" target="_blank" rel="external">Alpha Go</a>。也正是因为Alpha Go在围棋人机大战中里程碑式的胜利，人工智能迎来了新的春天。 <strong>本文也不免俗套，从Alpha Go说起，但希望能指明一些被忽视的但对Alpha Go棋力有深远影响的技术。</strong> 围棋人工智能大致可以分为三个阶段<a href="详见知乎Live：[深入浅出说围棋人工智能](https://www.zhihu.com/lives/784053023981719552)">^1</a> ：第一阶段以启发式算法为主，水平低于业余初段，代表软件即以静态势力函数为强项的<a href="https://zh.wikipedia.org/wiki/%E9%99%88%E5%BF%97%E8%A1%8C" target="_blank" rel="external">手谈</a>； 第二阶段以<a href="https://zh.wikipedia.org/zh-sg/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%A0%91%E6%90%9C%E7%B4%A2" target="_blank" rel="external">蒙特卡洛树搜索算法 </a>为代表，水平最高达到业余5段，比如说 <a href="http://senseis.xmp.net/?ZenGoProgram" target="_blank" rel="external">Zen</a> ，<a href="https://www.remi-coulom.fr/CrazyStone/" target="_blank" rel="external">Crazy Stone</a> ；第三阶段以 <code>深度学习</code> （<a href="https://en.wikipedia.org/wiki/Deep_learning" target="_blank" rel="external">Deep Learning</a>）以及 <code>增强学习</code> （<a href="https://en.wikipedia.org/wiki/Reinforcement_learning" target="_blank" rel="external">Reinforcement Learning</a>，也称强化学习）算法为突破，并战胜了人类职业九段棋手李世乭，这也就是Alpha Go的故事了。每每提到Alpha Go卓越的能力，往往归咎于深度学习的强大，但实际上增强学习算法也功不可没。这二者的结合被称之为 <code>深度增强学习</code> （<a href="https://deepmind.com/blog/deep-reinforcement-learning/" target="_blank" rel="external">Deep Reinforcement Learning</a>，DRL），最初见于DeepMind在Nature上发表的<a href="http://www.nature.com/nature/journal/v518/n7540/abs/nature14236.html" target="_blank" rel="external">Human-level control through deep reinforcement learning</a>。 <strong>本文试图从深度增强学习的角度来探讨通用人工智能的实现，并简要介绍了深度增强学习的基础知识、常见算法以及相关应用。</strong></p>
<h1 id="u5982_u4F55_u89E3_u51B3_u901A_u7528_u4EBA_u5DE5_u667A_u80FD_u7684_u96BE_u70B9"><a href="#u5982_u4F55_u89E3_u51B3_u901A_u7528_u4EBA_u5DE5_u667A_u80FD_u7684_u96BE_u70B9" class="headerlink" title="如何解决通用人工智能的难点"></a>如何解决通用人工智能的难点</h1><h2 id="u4E09_u5EA7_u5927_u5C71"><a href="#u4E09_u5EA7_u5927_u5C71" class="headerlink" title="三座大山"></a>三座大山</h2><p>创造出像你我一样具有自我意识和思考的人工智能估计是人世间最迷人的问题之一了吧，新的存在总是想窥探造物主的秘密。同 <code>P=NP</code> 问题一样，验证一个存在是否具有自我意识的难度（见<a href="https://zh.wikipedia.org/zh-sg/%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95" target="_blank" rel="external">图灵测试</a> 以及 <a href="https://zh.wikipedia.org/wiki/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4" target="_blank" rel="external">中文房间问题</a>） 同创造一个具有自我意识的存在的难度究竟关系如何，恐怕可以看做是判断自我意识是否能涌现的关键了吧。本文不讲那么上层次的人工智能，先来谈谈 <code>通用人工智能</code> 。按照维基百科的解释，</p>
<blockquote>
<p>强人工智能也指通用人工智能（artificial general intelligence，AGI），或具备执行一般智慧行为的能力。强人工智能通常把人工智能和意识、感性、知识和自觉等人类的特征互相连结。</p>
</blockquote>
<p>本文所指的通用人工智能，便是可以处理通用任务的人工智能。 <strong>具体而言，我认为通用人工智能应包括以下三大特点或者说难点：</strong></p>
<ul>
<li>通用任务：既能唱歌绘画、又能下棋写诗，最重要的是要尽量减少对 <code>领域知识</code> （<a href="https://en.wikipedia.org/wiki/Domain_knowledge" target="_blank" rel="external">Domain Knowledge</a>）的依赖。</li>
<li>学习能力：无论是通过逻辑推理的 <code>演绎法</code> 来学习，或者是基于经验和记忆的 <code>归纳法</code> 来学习，都要通过学习来提高处理通用任务的适用性。</li>
<li>自省能力：也可以说是关于学习的学习，即 <code>元认知</code> ，通过自省来纠偏行为。就像泰勒展开一样，我们大可以用低阶导数来逼近函数值，而无需考虑元认知的元认知这类高阶导数。</li>
</ul>
<h2 id="u89E3_u51B3_u4E4B_u9053"><a href="#u89E3_u51B3_u4E4B_u9053" class="headerlink" title="解决之道"></a>解决之道</h2><p>David Silver（Alpha Go的第一作者）曾在ICML2016的<a href="http://icml.cc/2016/tutorials/deep_rl_tutorial.pdf" target="_blank" rel="external">Tutorial: Deep Reinforcement Learning</a>讲到深度增强学习的前景</p>
<blockquote>
<p>General Intelligence = Reinforcement Learning + Deep Learning = Deep Reinforcement Learning &#x2013; David Silver</p>
</blockquote>
<p>更进一步，『Reinforcement Learning defines the objective』（RL中有什么样的映射关系），『Deep Learning gives the mechanism』（DL如何学习给定的映射关系）。 <strong>我很同意深度增强学习便是解决通用人工智能难点的核心。</strong> 首先关于通用任务，几乎任何任务的解决都可以看做一个从形式编码的输入到决策分布输出的映射，而非线性的神经网络便是很好的 <code>表征</code> （<a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning" target="_blank" rel="external">representation </a>）学习工具。其次，学习能力主要可分为演绎法和归纳法。增强学习就像是基于奖赏的演绎法，给定外界环境和相应的奖赏函数，我们最终产生合法的决策出来。深度学习就像是基于经验以及记忆的归纳法，给定输入输出，然后通过神经网络来学习表征。最后关于自省能力，这也是人工智能可以产生自我意识、并独立于人类存在的关键。自省从某种程度可以从增强学习来习得，通过不断试错以及奖赏，『增强/强化』自我的决策。但这种自省又受限于其存在的世界观，就像二维线段只能盲人摸象般地观测到三维球体，而三维球体却可以完整地观测二维线段。但总之，只要定义好了世界以及奖赏，我认为相应的自省能力就是在给定环境下不断优化自己的学习能力（即一阶导数大于零）。</p>
<h1 id="u4EC0_u4E48_u662F_u6DF1_u5EA6_u589E_u5F3A_u5B66_u4E60"><a href="#u4EC0_u4E48_u662F_u6DF1_u5EA6_u589E_u5F3A_u5B66_u4E60" class="headerlink" title="什么是深度增强学习"></a>什么是深度增强学习</h1><h2 id="u6DF1_u5EA6_u5B66_u4E60"><a href="#u6DF1_u5EA6_u5B66_u4E60" class="headerlink" title="深度学习"></a>深度学习</h2><blockquote>
<p>深度学习（deep learning）是机器学习拉出的分支，它试图使用包含复杂结构或由多重非线性变换构成的多个处理层对数据进行高层抽象的算法。 – 维基百科</p>
</blockquote>
<p><strong>根据维基百科的解释，深度学习是一种利用多层非线性变换处理网络结构来进行表征学习的通用框架。</strong> 得益于计算机性能的提升，深度学习重新对人工神经网络方法进行品牌重塑。其核心解决问题是，如何用尽可能少的领域知识，给定输入 $\boldsymbol{x}$ 和输出 $\boldsymbol{y}$ ，来学习从输入到输出的 <code>映射</code>  $\mathcal{DL}(\boldsymbol{x}, \boldsymbol{w})$ ，其中 $\boldsymbol{w}$是需要优化的参数， $\mathcal{DL}(\cdot)$在深度学习里由多层非线性网络结构进行表示（不同机器学习方法会有不同的刻画，比如随机森林、支持向量机等等），常见的架构方式包括深度神经网络（Deep Neural Networks），深度信念网络（Deep Belief Networks）、卷积神经网络（Convolutional Neural Networks）、递归神经网络（Recurrent/Recursice Neural Network）等等。下图直观的给出了这种逐层嵌套的网络结构，<br><img src="http://blog.greenwicher.com/2016/12/18/drl-general_ai-intro/Deep_Learning_Architecture.jpg" alt="深度学习架构"><br>具体而言，映射学习的过程是寻找最优的参数$\boldsymbol{w}$来最小化 <code>损失函数</code> $\mathcal{L}(\mathcal{DL}(\boldsymbol{x}, \boldsymbol{w}), \boldsymbol{y})$。这个损失函数衡量了真实和预测输出值之间的差异，常见的比如说对数损失函数、平方损失函数、指数损失函数、Hinge损失函数、各类Norm的损失函数等等[^2]。 同时为了提高模型的泛化能力，往往需要对损失函数进行 <code>正则化</code> （<a href="https://en.wikipedia.org/wiki/Regularization_(mathematics" target="_blank" rel="external">regularization</a>)）处理。一般需要尽量把损失函数转化为凸函数，如果函数不够光滑的话可以利用<a href="https://en.wikipedia.org/wiki/Moreau&#39;s_theorem" target="_blank" rel="external">Moreau-Yoshida regularization</a>进行处理以方便梯度的计算，最终利用 <code>梯度下降法</code> 来进行优化而得到 $\boldsymbol{w}^{<em>} =  \arg \min_{\boldsymbol{w}} \mathcal{L}(\mathcal{DL}(\boldsymbol{x}, \boldsymbol{w}), \boldsymbol{y})$，然后就可以利用 $\mathcal{DL}(\boldsymbol{x}, \boldsymbol{w}^{</em>})$来进行预测了。下图展示了神经网络的一种架构，以及各个隐含层所学习到的表征，可以看到不同隐含层有不同层次的抽象学习。比如说，有的负责颜色，有的负责形状，有的负责部件等等。<br><img src="http://blog.greenwicher.com/2016/12/18/drl-general_ai-intro/Neural_Networks_Layer_Explanation.jpg" alt="多层神经网络直观解释"></p>
<h2 id="u589E_u5F3A_u5B66_u4E60"><a href="#u589E_u5F3A_u5B66_u4E60" class="headerlink" title="增强学习"></a>增强学习</h2><blockquote>
<p>强化/增强学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。其灵感来源于心理学中的行为主义理论，即有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能获得最大利益的习惯性行为。这个方法具有普适性，因此在其他许多领域都有研究，例如博弈论、控制论、运筹学、信息论、仿真优化方法、多主体系统学习、群体智能、统计学以及遗传算法。 &#x2013;维基百科</p>
</blockquote>
<p><strong>简而言之，增强学习是一种基于环境反馈而做决策的通用框架。</strong> 具体到机器学习领域，很多人往往知道 <code>监督式学习</code> 和 <code>非监督式学习</code> （甚至半监督式学习），但却不知道第三类机器学习方法，即增强学习。 <strong>因为增强学习强调与环境的交互，我认为是离普遍意义上的人工智能更接近的一个领域。</strong> 这里『增强』或者『强化』的意思是，根据不断试错而得到的奖惩来不断增强对趋利决策的信念。David Silver下面这张图很好的总结了增强学习的研究主体，即 <code>Agent</code> 、 <code>Environment</code> 以及 <code>State</code> 。<br><img src="http://blog.greenwicher.com/2016/12/18/drl-general_ai-intro/Reinforcement_Learning_Configurations.png" alt="增强学习的核心要素"><br>首先在$t$时刻， Agent依据当前的状态$s<em>{t}$以及历史信息来决定下一轮的决策（ <code>action</code> ） $a</em>{t+1}$ 。然后给定当前的状态 $s<em>{t}$ 以及 Agent的决策 $a</em>{t+1}$ ，Environment决定下一轮 $t+1$ 的状态 $s<em>{t+1}$ 、给Agent的报酬（ <code>reward</code> ） $r</em>{t+1}$ 、以及它可观测到的其他信息 $o_{t+1}$ 。最后，循环往复直到任务完成。不同于Planning（规划）问题，Learning（学习）问题一开始并不知道Environment的全部情况，因此需要逐步试错学习环境以及调整自身决策。 <strong>关于奖赏的机制这里有一个假设，那就是假定所有的目标都可以被刻画为期望累积收益的最大化。</strong> 从上面的描述可以看到关于Agent，有三个很关键的组成要素，</p>
<ul>
<li><code>Policy function</code> （策略函数）：从状态到决策的映射<ul>
<li>Deterministic policy： $\pi(s<em>{t}) = a</em>{t+1}$</li>
<li>Stochastic policy： $\pi(s<em>{t}) = \mathbb{P}(a</em>{t+1} | s_{t})$</li>
</ul>
</li>
<li><code>Value function</code> （价值函数）：从状态以及决策到期望累积收益的映射<ul>
<li><a href="https://en.wikipedia.org/wiki/Bellman_equation" target="_blank" rel="external">Bellman equation</a> of <code>Q-value function</code> ： $Q^{\pi}(s<em>{t}, a</em>{t+1}) = E^{\pi}[r<em>{t+1} + \gamma r</em>{t+2} + \gamma^{2} r<em>{t+3} + \dotsc | s</em>{t}, a<em>{t+1}] = E^{\pi}[r</em>{t+1} + \gamma Q^{\pi}(s<em>{t+1}, a</em>{t+2}) | s<em>{t}, a</em>{t+1}]$</li>
<li>Bellman equation of <code>Optimal value function</code> ：$V(s<em>{t}) = Q^{*}(s</em>{t}, a<em>{t+1}) = \max</em>{\pi} Q^{\pi}(s<em>{t}, a</em>{t+1}) = E^{<em>}[r<em>{t+1} + \gamma \max</em>{a_{t+2}} Q^{</em>}(s<em>{t+1}, a</em>{t+2}) | s<em>{t}, a</em>{t+1}]$</li>
</ul>
</li>
<li><code>Model function</code> （环境函数）：从状态以及决策到环境决策的映射[^3]<ul>
<li>Deterministic environment： $e(s<em>{t}, a</em>{t+1}) = [s<em>{t+1}, r</em>{t+1}, o_{t+1}]$</li>
<li>Stochastic environment： $e(s<em>{t}, a</em>{t+1}) = \mathbb{P}([s<em>{t+1}, r</em>{t+1}, o<em>{t+1}] | s</em>{t}, a_{t+1})$</li>
</ul>
</li>
</ul>
<p>通过折现因子 $\gamma$ 的引入，Q-value function一来可以转化为贝尔曼方程并满足无后效性以及最优子结构的特征；并且多期的折现又比单纯的one-step lookahead贪婪策略更加具有远见。 <strong>总而言之，求解增强学习问题的核心实际上在于价值函数的贝尔曼方程，这也是动态规划里标准的状态转移方程，即定义好边界以及该方程后，就可以通过倒推法或者带记忆的递归予以解决。</strong> 不过增强学习也可以通过直接搜索最优策略或者学习环境的奖惩套路来解决。 <strong>实际上，这三个要素正是强化学习同深度学习结合的关键。</strong> 正如David Silver所说<a href="详见http://icml.cc/2016/tutorials/deep_rl_tutorial.pdf">^4</a>，</p>
<blockquote>
<p>Reinforcement Learning defines the objective. Deep Learning gives the mechanism. &#x2013; David Silver</p>
</blockquote>
<h2 id="u4E8C_u8005_u7684_u878D_u5408"><a href="#u4E8C_u8005_u7684_u878D_u5408" class="headerlink" title="二者的融合"></a>二者的融合</h2><p>对于复杂的任务以及环境而言，Q-value function实际上很难穷举的完的（针对每一个状态和决策都要给一个累积期望收益值），因此一般需要通过历史信息来估计这一函数。同样的，对Policy function和Model function也有类似的情况。 <strong>所以在给定增强学习三大求解目标（Policy-based, Value-based, Model-based）之后，我们便可以利用深度学习来利用历史输入输出来估计这三大目标函数。</strong></p>
<h1 id="u600E_u4E48_u5229_u7528_u6DF1_u5EA6_u589E_u5F3A_u5B66_u4E60_u89E3_u51B3_u95EE_u9898"><a href="#u600E_u4E48_u5229_u7528_u6DF1_u5EA6_u589E_u5F3A_u5B66_u4E60_u89E3_u51B3_u95EE_u9898" class="headerlink" title="怎么利用深度增强学习解决问题"></a>怎么利用深度增强学习解决问题</h1><p>正如上文的分析，David Silver将深度增强学习算法分为如下三大类<a href="5详见http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/intro_RL.pdf">^5</a>。 下文将先从增强学习的角度分析如何做决策，然后从深度学习的角度来分析如何学习相应的策略函数、估值函数以及环境函数。<br><img src="http://blog.greenwicher.com/2016/12/18/drl-general_ai-intro/RL_Agent_Taxonomy.png" alt=""></p>
<h2 id="Policy-based_DRL"><a href="#Policy-based_DRL" class="headerlink" title="Policy-based DRL"></a>Policy-based DRL</h2><p>下图展示了利用 <code>Policy Iteration Algorithm</code> 来解决增强学习问题的思路。即给定任意初始策略 $\pi<em>{0}(s)$ ，然后利用估值函数 $V</em>{0}(s)$ 对其评价，基于该估值函数对策略进一步优化得到 $\pi_{1}(s)$ 。循环这一过程，直至策略达到最优而不能进一步改善。<br><img src="http://blog.greenwicher.com/2016/12/18/drl-general_ai-intro/Policy_Iteration_Pseudo_Code.png" alt=""></p>
<p>至于在深度学习方面，首先对policy function进行参数化 $a = \pi(s, \boldsymbol{u})$，其中 $\boldsymbol{u}$ 为神经网络的参数。其次，参数化后的累积期望收益函数为 $V(\boldsymbol{u}) = E[r<em>{1} + \gamma r</em>{2} + \gamma^{2} r_{3} + \dotsc | \pi(\cdot, \boldsymbol{u})]$ 。然后，我们就可以得到 <code>策略梯度</code> （Policy Gradients），在随机性策略函数下为 $\frac{\partial V(\boldsymbol{u})}{\partial \boldsymbol{u}} = E[\frac{\partial log \pi (a | s, \boldsymbol{u})}{\partial \boldsymbol{u}} Q^{\pi}(s, a)]$ ，而在确定性策略函数下为 $\frac{\partial V(\boldsymbol{u})}{\partial \boldsymbol{u}} = E[\frac{\partial Q^{\pi}(s, a)}{\partial a} \frac{\partial a}{\partial \boldsymbol{u}}]$ 。最后，便可以利用梯度下降算法来寻找最优的神经网络参数 $\boldsymbol{u}$ [^6]。</p>
<h2 id="Value-based_DRL"><a href="#Value-based_DRL" class="headerlink" title="Value-based DRL"></a>Value-based DRL</h2><p>下图是解决增强学习问题的 <code>Value Iteration Algorithm</code> 的伪代码。即给定任意初始估值函数 $V(s)$ ，利用贝尔曼方程递推得逼近真实的估值函数。<br><img src="http://blog.greenwicher.com/2016/12/18/drl-general_ai-intro/Value_Iteration_Pseudo_Code.png" alt=""></p>
<p>至于深度学习方面，类似的，先对value function进行参数化 $Q(s, a, \boldsymbol{w}) \approx Q^{*}(s, a)$ ，那我们的目的就是找 $\boldsymbol{w}$ 。然后，就是优化损失函数 $L = (r + \gamma \max_{a} Q(s^{‘}, a^{‘}, \boldsymbol{w}) - Q(s, a, \boldsymbol{w}))^{2}$[^7]。David Silver在这里提到如果样本之间存在相关性或者收益函数非平稳，容易导致价值函数的不收敛，因此需要一些机制来予以解决。</p>
<h2 id="Model-based_DRL"><a href="#Model-based_DRL" class="headerlink" title="Model-based DRL"></a>Model-based DRL</h2><p>关于Model-based DRL，David Silver讲的比较少，主要举了Alpha Go的例子，即我们完美知道环境的信息（走子规则、胜负规则等等）。大致意思还是利用神经网络来代替真实的环境函数，也就是让Agent有能力预测环境下一期的状态以及收益等等，基于此来优化Agent的决策过程。下图是网上<a href="详见http://mlg.eng.cam.ac.uk/mlss09/mlss_slides/Littman_1.pdf">^8</a> 找到的 <code>Model Iteration Algorithm</code> 的伪代码，基本就是通过对状态转移函数以及奖惩函数的搜索，来估计价值函数。<br><img src="http://blog.greenwicher.com/2016/12/18/drl-general_ai-intro/Model_Iteration_Pseudo_Code.png" alt=""></p>
<h1 id="u6DF1_u5EA6_u589E_u5F3A_u5B66_u4E60_u6709_u54EA_u4E9B_u7528_u9014"><a href="#u6DF1_u5EA6_u589E_u5F3A_u5B66_u4E60_u6709_u54EA_u4E9B_u7528_u9014" class="headerlink" title="深度增强学习有哪些用途"></a>深度增强学习有哪些用途</h1><p><strong>可以看到凡是任务导向型，并且目标可以被奖惩函数刻画的，均可以利用深度增强学习来解决，所以其应用范围还是蛮广的。</strong> 以下举了深度增强学习的若干应用，视频均来自Youtube，因此需要科学上网。</p>
<h2 id="u6E38_u620F_u7B56_u7565"><a href="#u6E38_u620F_u7B56_u7565" class="headerlink" title="游戏策略"></a>游戏策略</h2><center><br>  <iframe width="560" height="315" src="https://www.youtube.com/embed/L4KBBAwF_bE" frameborder="0" allowfullscreen></iframe><br></center>

<h2 id="u673A_u5668_u4EBA_u63A7_u5236"><a href="#u673A_u5668_u4EBA_u63A7_u5236" class="headerlink" title="机器人控制"></a>机器人控制</h2><center><br>  <iframe width="560" height="315" src="https://www.youtube.com/embed/ZhsEKTo7V04" frameborder="0" allowfullscreen></iframe><br></center>

<h2 id="u65E0_u4EBA_u9A7E_u9A76"><a href="#u65E0_u4EBA_u9A7E_u9A76" class="headerlink" title="无人驾驶"></a>无人驾驶</h2><center><br>  <iframe width="560" height="315" src="https://www.youtube.com/embed/QK0LxA8FWq4" frameborder="0" allowfullscreen></iframe><br></center>

<h2 id="u63A2_u7D22_u73AF_u5883"><a href="#u63A2_u7D22_u73AF_u5883" class="headerlink" title="探索环境"></a>探索环境</h2><center><br>  <iframe width="560" height="315" src="https://www.youtube.com/embed/nMR5mjCFZCw" frameborder="0" allowfullscreen></iframe><br></center>

<h2 id="u5B66_u4F1A_u8D70_u8DEF"><a href="#u5B66_u4F1A_u8D70_u8DEF" class="headerlink" title="学会走路"></a>学会走路</h2><center><br>  <iframe width="560" height="315" src="https://www.youtube.com/embed/eFopkAceTGs" frameborder="0" allowfullscreen></iframe><br></center>

<h2 id="u5F00_u6E90_u6D4B_u8BD5_u5F00_u53D1_u5E73_u53F0"><a href="#u5F00_u6E90_u6D4B_u8BD5_u5F00_u53D1_u5E73_u53F0" class="headerlink" title="开源测试开发平台"></a>开源测试开发平台</h2><ul>
<li><a href="https://gym.openai.com/" target="_blank" rel="external">OpenAI Gym</a>以及<a href="https://universe.openai.com/" target="_blank" rel="external">OpenAI Universe</a></li>
<li><a href="https://github.com/deepmind/lab" target="_blank" rel="external">DeepMind Lab</a></li>
<li><a href="https://github.com/Microsoft/malmo#getting-started" target="_blank" rel="external">Malmo</a></li>
<li><a href="http://www.nature.com/news/tech-giants-open-virtual-worlds-to-bevy-of-ai-programs-1.21151" target="_blank" rel="external">Nature关于三大开源平台的对比：Tech giants open virtual worlds to bevy of AI programs</a></li>
</ul>
<h1 id="u7ED3_u8BED"><a href="#u7ED3_u8BED" class="headerlink" title="结语"></a>结语</h1><p><strong>如果说达尔文的进化论是人类关于自身起源的一次冲击，那么通用型人工智能的诞生便是对人类未来的另一次冲击。</strong> 在Alpha Go之前，人们认为人工智能战胜人类围棋高手大概还需要十多年的样子，然而技术的发展速度实在是不可想想。让我们扩大时间的尺度，想想十年前、百年前、千年前中国的样子，在看看我们现在的生活，不能说是天翻地覆，但显然得益于技术的发展，我们的生活有了更多的便捷。 <strong>也不禁畅想未来，说不定下个技术引爆点没有想象中的那么远，或许明年或许明天。</strong> 所以，对于大多数人而言，还是有必要提前接触这些前沿的领域，一来不至于自己到了未来成为新『文盲』，二来也不会沦落到被高新技术革了命。</p>
<h1 id="u5173_u4E8E_u3010_u6DF1_u5EA6_u589E_u5F3A_u5B66_u4E60_u3011_u7CFB_u5217_u7684_u8BF4_u660E"><a href="#u5173_u4E8E_u3010_u6DF1_u5EA6_u589E_u5F3A_u5B66_u4E60_u3011_u7CFB_u5217_u7684_u8BF4_u660E" class="headerlink" title="关于【深度增强学习】系列的说明"></a>关于【深度增强学习】系列的说明</h1><p>对于我自己而言，写【深度增强学习】这一系列文章，除了自己的兴趣之外，其实增强学习和我的研究方向（仿真优化）也略微相关，希望能从中获取些新知识和新想法。初步打算本系列文章以<a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" target="_blank" rel="external">David Silver的公开课</a> 以及 <a href="http://rll.berkeley.edu/deeprlcourse/" target="_blank" rel="external">UC Berkeley的CS294</a>为蓝本，着重在增强学习领域，陆续会补充深度学习的相关探讨。记录自己的所学所思，力图抓住主要核心。毕竟吾生也有涯，而知也无涯。以有涯随无涯，殆已！但学习是一辈子的事情，所以时不时也会重新补充或者修改这些文章。本人初涉深度增强学习领域，还希望各位学界业界大牛多多指正文章中不当之处，互相切磋，谢谢！</p>
<h1 id="u5EF6_u4F38_u9605_u8BFB"><a href="#u5EF6_u4F38_u9605_u8BFB" class="headerlink" title="延伸阅读"></a>延伸阅读</h1><ul>
<li>公开课<ul>
<li><a href="http://rll.berkeley.edu/deeprlcourse/" target="_blank" rel="external">UCB CS294 Deep Reinforcement Learning</a></li>
<li><a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" target="_blank" rel="external">UCL Course on Reinforcement Learning</a></li>
</ul>
</li>
<li>基础介绍<ul>
<li><a href="http://icml.cc/2016/tutorials/deep_rl_tutorial.pdf" target="_blank" rel="external">Tutorial: Deep Reinforcement Learning</a></li>
<li><a href="https://deepmind.com/blog/deep-reinforcement-learning/" target="_blank" rel="external">Deep Reinforcement Learning | DeepMind</a></li>
</ul>
</li>
<li>书籍<ul>
<li><a href="https://webdocs.cs.ualberta.ca/~sutton/book/bookdraft2016sep.pdf" target="_blank" rel="external">《Reinforcement Learning: An Introduction》</a></li>
<li><a href="https://sites.ualberta.ca/~szepesva/RLBook.html" target="_blank" rel="external">《Algorithms for Reinforcement Learning》</a></li>
<li><a href="http://www.deeplearningbook.org/" target="_blank" rel="external">《Deep Learning》</a></li>
</ul>
</li>
<li>论文<ul>
<li><a href="https://sites.google.com/site/deeprlnips2016/" target="_blank" rel="external">Deep Reinforcement Learning Workshop, NIPS 2016</a></li>
<li><a href="http://rll.berkeley.edu/deeprlworkshop/" target="_blank" rel="external">Deep Reinforcement Learning Workshop, NIPS 2015</a></li>
<li><a href="https://github.com/muupan/deep-reinforcement-learning-papers" target="_blank" rel="external">Deep Reinforcement Learning Papers</a></li>
<li><a href="https://github.com/junhyukoh/deep-reinforcement-learning-papers" target="_blank" rel="external">Deep Reinforcement Learning Papers CONT’D</a></li>
<li><a href="https://github.com/HFTrader/DeepLearningBook/blob/master/DeepLearningPapers.md" target="_blank" rel="external">Deep Learning Papers</a></li>
</ul>
</li>
<li>资源列表<ul>
<li><a href="https://github.com/aikorea/awesome-rl" target="_blank" rel="external">Awesome Reinforcement Learning List</a></li>
<li><a href="https://github.com/ChristosChristofidis/awesome-deep-learning" target="_blank" rel="external">Awesome Deep Learning List</a></li>
</ul>
</li>
<li>其他<ul>
<li><a href="http://karpathy.github.io/2016/05/31/rl/" target="_blank" rel="external">Deep Reinforcement Learning: Pong from Pixels</a></li>
<li><a href="https://www.zhihu.com/question/49787932" target="_blank" rel="external">RL两大类算法的本质区别？（Policy Gradient 和 Q-Learning)</a></li>
<li><a href="http://www.slideshare.net/tw_dsconf/ss-62245351" target="_blank" rel="external">DSC 2016 系列活動：李宏毅 / 一天搞懂深度學習</a></li>
</ul>
</li>
</ul>
<p>[^2]: 各类损失函数的定义及应用具体请见 <a href="http://www.csuldw.com/2016/03/26/2016-03-26-loss-function/" target="_blank" rel="external">http://www.csuldw.com/2016/03/26/2016-03-26-loss-function/</a></p>
<p>[^3]: 在David Silver的Tutorial里并没有详细讲Model函数的刻画，这里的映射仅仅是我自己的理解，即通过model来作为刻画环境的媒介</p>
<p>[^6]: 这个大概就是Deep Policy Networks(DPN)的大致思路</p>
<p>[^7]: 这个大概就是Deep Q-Networks(DQN)的大致思路</p>

	
  </div>
</div>
		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> Jan 3 2017 </div>
			<div class="article-title"><a href="/2017/01/03/codeforces-problemset/" title="简要介绍如何科学地刷算法题，来提高自己解决问题的能力，并利用爬虫抓取Codeforces的题库，来分析题目难度以及算法分类的关系">Codeforces科学刷题指南，一图一表便够了</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
           
  	      <div class="thumbnail"><a href="/2017/01/03/codeforces-problemset/"><img src="/2017/01/03/codeforces-problemset/codeforces-logo.png" alt="Codeforces科学刷题指南，一图一表便够了"  class="nofancybox"></a>
           
		</div>
	
        
          <p>
&#x65E0;&#x8BBA;&#x505A;&#x4EC0;&#x4E48;&#x4E8B;&#xFF0C;&#x591A;&#x5C1D;&#x8BD5;&#x3001;&#x627E;&#x5957;&#x8DEF;&#x3001;&#x7136;&#x540E;&#x523B;&#x610F;&#x7EC3;&#x4E60;&#x90FD;&#x662F;&#x81F3;&#x5173;&#x91CD;&#x8981;&#x7684;&#x3002;&#x5BF9;&#x4FE1;&#x606F;&#x79D1;&#x5B66;&#x7ADE;&#x8D5B;&#xFF08;Olympiad in Informatics&#xFF09;&#x7231;&#x597D;&#x8005;&#x6765;&#x8BF4;&#xFF0C;&#x627E;&#x5957;&#x8DEF;&#x7684;&#x5173;&#x952E;&#x5C31;&#x662F;&#x591A;&#x5237;&#x9898;&#x3002;&#x7136;&#x800C;&#x9898;&#x6D77;&#x832B;&#x832B;&#xFF0C;&#x5355;&#x4EE5;Codeforces&#x6765;&#x8BF4;&#xFF0C;&#x622A;&#x6B62;2017&#x5E74;1&#x6708;3&#x65E5;&#xFF0C;&#x603B;&#x5171;&#x6709;3206&#x9053;&#x9898;&#x3002;&#x6362;&#x8A00;&#x4E4B;&#xFF0C;&#x5982;&#x679C;&#x4E00;&#x4E2A;&#x4EBA;&#x8DB3;&#x591F;&#x52E4;&#x594B;&#xFF0C;&#x80FD;&#x591F;&#x4E00;&#x5929;&#x5237;&#x4E09;&#x9053;&#x9898;&#xFF0C;&#x90A3;&#x4E5F;&#x5F97;&#x5FEB;&#x4E09;&#x5E74;&#x624D;&#x80FD;&#x628A;&#x9898;&#x76EE;&#x5237;&#x5B8C;&#xFF0C;&#x800C;&#x4E14;&#x9898;&#x76EE;&#x6570;&#x91CF;&#x8FD8;&#x5728;&#x6269;&#x5145;&#x3002;&#x6240;&#x4EE5;&#x76F2;&#x76EE;&#x7684;&#x5237;&#x9898;&#x7B80;&#x76F4;&#x662F;&#x6D6A;&#x8D39;&#x751F;&#x547D;&#xFF0C;&#x672C;&#x4EBA;&#x4ECE;16&#x5E74;&#x4E0A;&#x534A;&#x5E74;&#x4E00;&#x76F4;&#x6309;&#x7167;&#x9898;&#x76EE;&#x89E3;&#x51B3;&#x4EBA;&#x6570;&#x4ECE;&#x9AD8;&#x5230;&#x4F4E;&#x6392;&#x5E8F;&#xFF0C;&#x4E0D;&#x65AD;&#x7684;&#x5237;&#x6C34;&#x9898;&#x3002;&#x663E;&#x7136;&#x6613;&#x89C1;&#xFF0C;&#x5237;&#x6C34;&#x9898;&#x7684;&#x540E;&#x679C;&#x5C31;&#x662F;&#x6CA1;&#x6709;&#x957F;&#x8FDB;&#xFF0C;&#x719F;&#x6089;&#x7684;&#x8FD8;&#x662F;&#x719F;&#x6089;&#xFF0C;&#x4E0D;&#x61C2;&#x7684;&#x8FD8;&#x662F;&#x4E0D;&#x61C2;&#xFF0C;&#x552F;&#x4E00;&#x8BA9;&#x81EA;&#x5DF1;&#x5F00;&#x5FC3;&#x7684;&#x5C31;&#x662F;&#x5237;&#x9898;&#x6570;&#x91CF;&#x7684;&#x7D2F;&#x79EF;&#x3002;&#x6240;&#x4EE5;&#x79D1;&#x5B66;&#x5237;&#x9898;&#x7684;&#x672C;&#x8D28;&#x5728;&#x4E8E;&#x4E0D;&#x65AD;&#x6311;&#x6218;&#x65B0;&#x9AD8;&#x5EA6;&#xFF0C;&#x5728;&#x4E00;&#x4E2A;&#x5E73;&#x53F0;&#x7EC3;&#x4E60;&#x8DB3;&#x591F;&#x4E45;&#x8DB3;&#x591F;&#x719F;&#x7EC3;&#x4E4B;&#x540E;&#xFF0C;&#x5C31;&#x8981;&#x8FDB;&#x5165;&#x4E0B;&#x4E00;&#x4E2A;&#x96BE;&#x5EA6;&#x5E73;&#x53F0;&#x3002;&#x4E3A;&#x4E86;&#x65B9;&#x4FBF;&#x5927;&#x5BB6;&#xFF0C;&#x6211;&#x628A;Codeforces&#x4E0A;&#x622A;&#x6B62;2017&#x5E74;1&#x6708;3&#x65E5;&#x7684;&#x6240;&#x6709;&#x9898;&#x76EE;&#x7684;&#x57FA;&#x672C;&#x4FE1;&#x606F;&#x7528;&#x722C;&#x866B;&#x6536;&#x96C6;&#x4E86;&#x4E0B;&#x6765;&#xFF0C;&#x5E76;&#x5B58;&#x50A8;&#x5230;excel&#x91CC;&#x3002;&#x66F4;&#x8FDB;&#x4E00;&#x6B65;&#xFF0C;&#x672C;&#x6587;&#x8BD5;&#x56FE;&#x5206;&#x6790;&#x4E0D;&#x540C;&#x7B97;&#x6CD5;&#x5728;&#x4E0D;&#x540C;&#x96BE;&#x5EA6;&#x7B49;&#x7EA7;&#x4E0A;&#x7684;&#x51FA;&#x73B0;&#x9891;&#x7387;&#x5206;&#x5E03;&#xFF0C;&#x4EE5;&#x53CA;&#x4E0D;&#x540C;&#x7B97;&#x6CD5;&#x5728;&#x4E0D;&#x540C;&#x96BE;&#x5EA6;&#x7B49;&#x7EA7;&#x4E0A;&#x88AB;&#x89E3;&#x51B3;&#x6B21;&#x6570;&#x7684;&#x5206;&#x5E03;&#x3002;&#x6700;&#x540E;&#xFF0C;&#x6211;&#x4F1A;&#x7B80;&#x8981;&#x4ECB;&#x7ECD;&#x7684;&#x6211;&#x7684;&#x5237;&#x9898;&#x89C2;&#xFF0C;&#x4EE5;&#x53CA;&#x5982;&#x4F55;&#x722C;&#x53D6;Codeforces&#x4E0A;&#x7684;&#x4FE1;&#x606F;&#x3002;
</p>
          <!-- only display read_more button if there's more to display -->
	  <a type="button" href="/2017/01/03/codeforces-problemset/#more" class="btn btn-default more">进去看看</a>
	
  </div>
</div>
		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> Jan 1 2017 </div>
			<div class="article-title"><a href="/2017/01/01/hello-2017/" title="我的2017年规划">Hello 2017</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
           
  	      <div class="thumbnail"><a href="/2017/01/01/hello-2017/"><img src="/2017/01/01/hello-2017/dragon.jpg" alt="Hello 2017"  class="nofancybox"></a>
           
		</div>
	
        
          <p>
&#x8BA1;&#x5212;&#x3001;&#x7EC4;&#x7EC7;&#x3001;&#x9886;&#x5BFC;&#x3001;&#x63A7;&#x5236;&#xFF0C;&#x8FD9;&#x6050;&#x6015;&#x662F;&#x5B66;&#x8FC7;&#x7BA1;&#x7406;&#x7684;&#x4EBA;&#x90FD;&#x8033;&#x719F;&#x80FD;&#x8BE6;&#x7684;&#x56DB;&#x4E2A;&#x8BCD;&#x3002;&#x51E1;&#x4E8B;&#x9884;&#x5219;&#x7ACB;&#xFF0C;&#x4E0D;&#x9884;&#x5219;&#x5E9F;&#x3002;&#x6211;&#x60F3;&#x76EE;&#x6807;&#x8FD8;&#x662F;&#x8BB2;&#x51FA;&#x6765;&#x3001;&#x5199;&#x51FA;&#x6765;&#x7684;&#x6BD4;&#x8F83;&#x597D;&#xFF0C;&#x4E00;&#x6765;&#x6709;&#x4E2A;&#x9776;&#x5B50;&#x77E5;&#x9053;&#x81EA;&#x5DF1;&#x8981;&#x505A;&#x4EC0;&#x4E48;&#xFF0C;&#x4E8C;&#x6765;&#x5FC3;&#x91CC;&#x53EF;&#x4EE5;&#x60E6;&#x8BB0;&#x7740;&#x4E5F;&#x7B97;&#x662F;&#x4E00;&#x79CD;&#x97AD;&#x7B56;&#xFF0C;&#x4E09;&#x6765;&#x4E5F;&#x6709;&#x4E2A;&#x76D1;&#x7763;&#x7ACB;flag&#x7684;&#x610F;&#x5473;&#x3002;&#x5176;&#x5B9E;&#x5927;&#x90E8;&#x5206;&#x7684;&#x76EE;&#x6807;&#xFF0C;&#x65E0;&#x5916;&#x4E4E;&#x5C31;&#x662F;&#x9760;&#x65F6;&#x95F4;&#x6765;&#x6362;&#x53D6;&#x7ED3;&#x679C;&#xFF0C;&#x6709;&#x4E2A;&#x9636;&#x6BB5;&#x6027;&#x7684;&#x8BA1;&#x5212;&#x4E5F;&#x597D;&#x5BF9;&#x6297;&#x81EA;&#x5DF1;&#x7684;&#x62D6;&#x5EF6;&#x75C7;&#xFF0C;&#x8981;&#x4E0D;&#x5C31;&#x9677;&#x5165;&#x81EA;&#x5DF1;&#x7684;&#x8212;&#x9002;&#x533A;&#x65E0;&#x6CD5;&#x524D;&#x8FDB;&#x3002;&#x5C31;&#x50CF;&#x9CA4;&#x9C7C;&#x8DC3;&#x9F99;&#x95E8;&#x4E00;&#x6837;&#xFF0C;&#x8DE8;&#x8FC7;&#x4E86;&#x8FD9;&#x4E2A;&#x69DB;&#xFF0C;&#x624D;&#x80FD;&#x6709;&#x65B0;&#x7684;&#x5E73;&#x53F0;&#x548C;&#x89C6;&#x91CE;&#x3002;&#x611F;&#x89C9;&#x6BD5;&#x4E1A;&#x4E24;&#x5E74;&#x534A;&#xFF0C;&#x5468;&#x56F4;&#x7684;&#x540C;&#x5B66;&#x90FD;&#x5728;&#x5927;&#x8E0F;&#x6B65;&#x7684;&#x524D;&#x8FDB;&#xFF0C;&#x800C;&#x6211;&#x8FD8;&#x5728;&#x539F;&#x5730;&#x8E0F;&#x6B65;&#xFF0C;&#x5B9E;&#x5728;&#x662F;&#x592A;&#x60ED;&#x6127;&#x4E86;&#x3002;&#x5728;&#x8FD9;&#x91CC;&#x5217;&#x51FA;&#x6211;2017&#x5E74;&#x7684;&#x5C0F;&#x76EE;&#x6807;&#xFF0C;&#x901A;&#x8FC7;&#x6BCF;&#x4E2A;&#x5B63;&#x5EA6;&#x7684;&#x8FFD;&#x8E2A;&#x4EE5;&#x53CA;&#x6821;&#x6B63;&#xFF0C;&#x5E0C;&#x671B;&#x5728;&#x65B0;&#x7684;&#x4E00;&#x5E74;&#x80FD;&#x6709;&#x6240;&#x6536;&#x83B7;&#x5427;&#x3002;
</p>
          <!-- only display read_more button if there's more to display -->
	  <a type="button" href="/2017/01/01/hello-2017/#more" class="btn btn-default more">进去看看</a>
	
  </div>
</div>
		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> Dec 31 2016 </div>
			<div class="article-title"><a href="/2016/12/31/good-bye-2016/" title="我的2016年总结">Good Bye 2016</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
           
  	      <div class="thumbnail"><a href="/2016/12/31/good-bye-2016/"><img src="/2016/12/31/good-bye-2016/2016_monkey.jpg" alt="Good Bye 2016"  class="nofancybox"></a>
           
		</div>
	
        
          <p>
&#x98CE;&#x8FC7;&#x7559;&#x58F0;&#xFF0C;&#x96C1;&#x8FC7;&#x7559;&#x75D5;&#x3002;&#x4E00;&#x5929;&#x53C8;&#x4E00;&#x5929;&#xFF0C;&#x4E00;&#x5E74;&#x53C8;&#x4E00;&#x5E74;&#xFF0C;&#x603B;&#x89C9;&#x5F97;&#x5C0F;&#x65F6;&#x5019;&#x7684;&#x65F6;&#x5149;&#x5F88;&#x6F2B;&#x957F;&#xFF0C;&#x800C;&#x8D8A;&#x957F;&#x8D8A;&#x5927;&#x5374;&#x89C9;&#x5F97;&#x65F6;&#x95F4;&#x98DE;&#x901D;&#xFF0C;&#x7A0D;&#x4E0D;&#x7559;&#x795E;&#x81EA;&#x5DF1;&#x5C31;&#x8001;&#x4E86;&#x3002;&#x5173;&#x4E8E;&#x8FD9;&#x4E2A;&#x65F6;&#x95F4;&#x76F8;&#x5BF9;&#x6027;&#xFF0C;&#x6709;&#x4EBA;&#x8FD9;&#x6837;&#x89E3;&#x91CA;&#x9053;&#xFF0C;&#x5047;&#x5982;&#x4F60;&#x4ECA;&#x5E74; \(N\) &#x5C81;&#xFF0C;&#x90A3;&#x4E48;&#x8FD9;&#x4E00;&#x5E74;&#x76F8;&#x5F53;&#x4E8E;&#x4F60;&#x4EBA;&#x751F;&#x4E2D;&#x7684; \(1/N\) &#xFF0C;&#x81EA;&#x7136;&#x5E74;&#x9F84;&#x8D8A;&#x5927;&#x5BF9;&#x65F6;&#x95F4;&#x6D41;&#x901D;&#x7684;&#x654F;&#x611F;&#x4E5F;&#x5C31;&#x8D8A;&#x6765;&#x8D8A;&#x5C0F;&#x3002;&#x6362;&#x53E5;&#x8BDD;&#x8BB2;&#xFF0C;&#x65F6;&#x95F4;&#x5BF9;&#x4EBA;&#x7684;&#x6548;&#x7528;&#x662F;&#x8FB9;&#x9645;&#x9012;&#x51CF;&#x7684;&#x3002;&#x5E74;&#x5C11;&#x65F6;&#x4E00;&#x65E0;&#x6240;&#x77E5;&#xFF0C;&#x7528;20%&#x65F6;&#x95F4;&#x5B66;&#x4E60;&#x4E86;80%&#x7684;&#x6E90;&#x5934;&#x77E5;&#x8BC6;&#xFF1B;&#x957F;&#x5927;&#x540E;&#x6709;&#x6240;&#x653B;&#xFF0C;&#x7528;80%&#x7684;&#x65F6;&#x95F4;&#x5B66;&#x4E60;&#x6216;&#x8005;&#x63D0;&#x51FA;&#x4E86;20%&#x7684;&#x6269;&#x5C55;&#x6027;&#x77E5;&#x8BC6;&#x3002;&#x5C3D;&#x7BA1;&#x5982;&#x6B64;&#xFF0C;&#x629B;&#x5F00;&#x6570;&#x5B57;&#x800C;&#x8A00;&#xFF0C;&#x8FD9;2016&#x5E74;&#x65E0;&#x8BBA;&#x5BF9;&#x8C01;&#x800C;&#x8BB2;&#xFF0C;&#x90FD;&#x662F;&#x9C9C;&#x6D3B;&#x7684;&#x4E00;&#x5E74;&#x3002;&#x5C31;&#x50CF;&#x6BCF;&#x4E2A;&#x4EBA;&#x90FD;&#x662F;&#x4E00;&#x672C;&#x4E66;&#xFF0C;&#x6709;&#x4E86;&#x9152;&#xFF0C;&#x6709;&#x4E86;&#x89C2;&#x4F17;&#xFF0C;&#x4FBF;&#x6709;&#x4E86;&#x6545;&#x4E8B;&#x3002;&#x8D76;&#x5728;&#x8FD9;2016&#x5E74;&#x7684;&#x5C3E;&#x5DF4;&#x4E0A;&#xFF0C;&#x8BA9;&#x6211;&#x505A;&#x4E00;&#x56DE;&#x77AC;&#x95F4;&#x6536;&#x85CF;&#x5BB6;&#xFF0C;&#x7528;&#x5149;&#x5F71;&#x6765;&#x8BB0;&#x5F55;&#x6211;&#x7684;2016&#x5E74;&#x3002;&#x8C22;&#x8C22;2016&#x5E74;&#x6211;&#x9047;&#x5230;&#x7684;&#x6240;&#x6709;&#x4EBA;&#xFF0C;&#x5982;&#x679C;&#x6CA1;&#x6709;&#x4F60;&#x4EEC;&#xFF0C;&#x8FD9;&#x4E5F;&#x4E0D;&#x4F1A;&#x6210;&#x4E3A;&#x6211;&#x7684;2016&#x5E74;&#x3002;
</p>
<ul class="org-ul">
<li>&#x5E74;&#x521D;&#x7EA6;&#x5B9A;&#x8981;&#x53D1;&#x8BBA;&#x6587;&#xFF0C;&#x7ECF;&#x8FC7;&#x534A;&#x5E74;&#x7684;&#x5BA1;&#x7A3F;&#x518D;&#x56DB;&#x4E2A;&#x6708;&#x7684;&#x4FEE;&#x6539;&#x5E0C;&#x671B;&#x4E00;&#x5207;&#x80FD;&#x9042;&#x613F;&#x5427;&#xFF0C;&#x53E6;&#x5916;&#x4E00;&#x7BC7;QE&#x7ED3;&#x675F;&#x4E4B;&#x540E;&#x5C31;&#x6CA1;&#x600E;&#x4E48;&#x7BA1;&#x4E86;&#x3002;
</li>
<li>&#x5E74;&#x521D;&#x8BF4;&#x4F46;&#x6C42;&#x8650;&#x72D7;&#xFF0C;&#x4E5F;&#x4ECE;&#x4E00;&#x4EFD;&#x53CB;&#x60C5;&#x6536;&#x83B7;&#x5230;&#x4E86;&#x771F;&#x631A;&#x7684;&#x7231;&#x60C5;&#xFF0C;&#x867D;&#x7136;&#x6709;&#x7740;&#x5404;&#x79CD;&#x963B;&#x9694;&#xFF0C;&#x4F46;&#x8FD8;&#x662F;&#x8C22;&#x8C22;&#x4F60;&#x7ED9;&#x6211;&#x7684;&#x5FEB;&#x4E50;&#x65F6;&#x5149;&#x3002;
</li>
<li>&#x5E74;&#x521D;&#x8BF4;&#x8981;&#x5F00;&#x53D1;&#x91CF;&#x5316;&#x4EA4;&#x6613;&#x7CFB;&#x7EDF;&#xFF0C;&#x867D;&#x7136;&#x6CA1;&#x6709;&#x5B9E;&#x73B0;&#xFF0C;&#x4F46;&#x4E5F;&#x501F;&#x7740;&#x4ECA;&#x5E74;&#x521D;&#x9732;&#x950B;&#x8292;&#x7684;&#x5404;&#x5927;&#x91CF;&#x5316;&#x5E73;&#x53F0;&#x5B9E;&#x73B0;&#x4E86;&#x51E0;&#x4E2A;&#x8FD8;&#x51D1;&#x6D3B;&#x7684;&#x7B56;&#x7565;&#x3002;
</li>
<li>&#x5E74;&#x521D;&#x60F3;&#x7740;&#x5728;codeforces&#x4E0A;&#x518D;&#x8FDB;&#x4E00;&#x6B65;&#xFF0C;&#x5237;&#x4E86;&#x534A;&#x5E74;&#x9898;&#x76F4;&#x5230;&#x5E74;&#x5C3E;&#x91CD;&#x65B0;&#x62FE;&#x8D77;&#xFF0C;&#x53D1;&#x73B0;&#x81EA;&#x5DF1;&#x53EA;&#x662F;&#x5728;&#x8212;&#x9002;&#x533A;&#x5212;&#x6C34;&#x3002;
</li>
</ul>
          <!-- only display read_more button if there's more to display -->
	  <a type="button" href="/2016/12/31/good-bye-2016/#more" class="btn btn-default more">进去看看</a>
	
  </div>
</div>
		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> Dec 24 2016 </div>
			<div class="article-title"><a href="/2016/12/24/drl-from_mab_to_mcts/" title="两个重要的增强学习问题：多臂赌博机问题和蒙特卡洛树搜索">深度增强学习【2】从多臂赌博机问题到蒙特卡洛树搜索</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
           
  	      <div class="thumbnail"><a href="/2016/12/24/drl-from_mab_to_mcts/"><img src="/2016/12/24/drl-from_mab_to_mcts/Las_Vegas_slot_machines.jpg" alt="深度增强学习【2】从多臂赌博机问题到蒙特卡洛树搜索"  class="nofancybox"></a>
           
		</div>
	
        
          <p>
&#x6709;&#x7684;&#x4EBA;&#x82E6;&#x4E8E;&#x6CA1;&#x6709;&#x9009;&#x62E9;&#x53EF;&#x9009;&#xFF0C;&#x53EA;&#x80FD;&#x4E00;&#x6761;&#x8DEF;&#x8D70;&#x5230;&#x9ED1;&#xFF1B;&#x800C;&#x6709;&#x7684;&#x4EBA;&#x9009;&#x62E9;&#x8FC7;&#x591A;&#x3001;&#x6743;&#x8861;&#x8FC7;&#x591A;&#xFF0C;&#x53CD;&#x800C;&#x65E0;&#x4ECE;&#x4E0B;&#x624B;&#xFF0C;&#x76F8;&#x5F53;&#x4E8E;&#x6CA1;&#x505A;&#x9009;&#x62E9;&#x3002;&#x7EA6;&#x675F;&#x592A;&#x591A;&#x6709;&#x7EA6;&#x675F;&#x592A;&#x591A;&#x7684;&#x70E6;&#x607C;&#xFF0C;&#x592A;&#x8FC7;&#x81EA;&#x7531;&#x6709;&#x592A;&#x8FC7;&#x81EA;&#x7531;&#x7684;&#x70E6;&#x607C;&#xFF0C;&#x8FD9;&#x4E5F;&#x7B97;&#x662F;&#x4E00;&#x79CD; <a href="http://wiki.mbalib.com/wiki/%E8%B5%84%E6%BA%90%E8%AF%85%E5%92%92">&#x8D44;&#x6E90;&#x8BC5;&#x5492;</a> &#x5427;&#x3002; <b>&#x7136;&#x800C;&#x9762;&#x5BF9;&#x9009;&#x62E9;&#x56F0;&#x96BE;&#x75C7;&#xFF0C;&#x5230;&#x5E95;&#x6709;&#x6CA1;&#x6709;&#x7075;&#x4E39;&#x5999;&#x836F;&#x6765;&#x89E3;&#x51B3;&#x5B83;&#x3002;&#x79D1;&#x5B66;&#x5BB6;&#x8BF4;&#xFF0C;&#x5FC5;&#x987B;&#x6709;&#xFF01;</b> &#x5148;&#x6765;&#x8003;&#x8651;&#x4E00;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;&#x67D0;&#x5929;&#x4F60;&#x8D70;&#x4E86;&#x72D7;&#x5C4E;&#x8FD0;&#x5929;&#x4E0A;&#x6389;&#x4E0B;&#x4E86;1000&#x5757;&#x94B1;&#xFF0C;&#x4F60;&#x89C9;&#x5F97;&#x81EA;&#x5DF1;&#x7684;&#x8FD0;&#x6C14;&#x6B63;&#x65FA;&#xFF0C;&#x800C;&#x4E14;&#x53CD;&#x6B63;&#x662F;&#x4E0D;&#x4E49;&#x4E4B;&#x8D22;&#xFF0C;&#x4E0D;&#x5982;&#x53BB;&#x8D4C;&#x573A;&#x6765;&#x4EE5;&#x5C0F;&#x535A;&#x5927;&#x3002;&#x8D5A;&#x4E86;&#x7B97;&#x81EA;&#x5DF1;&#x7684;&#xFF0C;&#x8D54;&#x4E86;&#x5C31;&#x5F53;&#x6CA1;&#x6361;&#x8FC7;&#x8FD9;&#x94B1;&#x3002;&#x4F60;&#x5174;&#x51B2;&#x51B2;&#x7684;&#x8DD1;&#x53BB;&#x4E86;&#x8D4C;&#x573A;&#x53BB;&#x73A9;&#x8001;&#x864E;&#x673A;&#xFF0C;&#x7136;&#x800C;&#x5230;&#x4E86;&#x8D4C;&#x573A;&#x5374;&#x50BB;&#x4E86;&#x773C;&#xFF0C;&#x7ADF;&#x7136;&#x6709;200&#x53F0;&#x8001;&#x864E;&#x673A;&#xFF01;&#x968F;&#x4FBF;&#x9009;&#x4E00;&#x4E2A;&#x8001;&#x864E;&#x673A;&#x53EF;&#x4E0D;&#x884C;&#xFF0C;&#x56E0;&#x4E3A;&#x4F60;&#x542C;&#x4EBA;&#x8BF4;&#x8FC7;&#x6709;&#x7684;&#x8001;&#x864E;&#x673A;&#x8D62;&#x7387;&#x6BD4;&#x8F83;&#x9AD8;&#xFF0C;&#x6709;&#x7684;&#x6BD4;&#x8F83;&#x4F4E;&#x3002;&#x90A3;&#x4E48;&#x95EE;&#x9898;&#x6765;&#x4E86;&#xFF0C;&#x7ED9;&#x5B9A;&#x8FD9;1000&#x5757;&#x94B1;&#xFF0C;&#x5047;&#x5B9A;&#x73A9;&#x4E00;&#x6B21;&#x8001;&#x864E;&#x673A;&#x8981;&#x652F;&#x4ED8;1&#x5757;&#x94B1;&#xFF0C;&#x90A3;&#x4E48;&#x5E94;&#x8BE5;&#x73A9;&#x54EA;&#x4E9B;&#x8001;&#x864E;&#x673A;&#x3001;&#x4EE5;&#x600E;&#x6837;&#x7684;&#x987A;&#x5E8F;&#x53BB;&#x73A9;&#x624D;&#x80FD;&#x4F7F;&#x5F97;&#x81EA;&#x5DF1;&#x7684;&#x7D2F;&#x79EF;&#x6536;&#x76CA;&#x6700;&#x5927;&#xFF1F;&#x5728; <a href="http://blog.greenwicher.com/2016/12/18/drl-general_ai-intro/">&#x4E0A;&#x7BC7;&#x6DF1;&#x5EA6;&#x589E;&#x5F3A;&#x5B66;&#x4E60;&#x7CFB;&#x5217;&#x6587;&#x7AE0;</a>&#xFF0C; &#x6211;&#x4EEC;&#x8BB2;&#x5230;&#x4E86;Alpha Go&#x4E2D;&#x7684;&#x4E24;&#x4E2A;&#x5173;&#x952E;&#x6280;&#x672F;&#xFF1A;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x548C;&#x589E;&#x5F3A;&#x5B66;&#x4E60;&#x3002; <b>&#x672C;&#x6587;&#x5C06;&#x9996;&#x5148;&#x4ECB;&#x7ECD; <code>&#x591A;&#x81C2;&#x8D4C;&#x535A;&#x673A;&#x95EE;&#x9898;</code>  &#xFF08;<a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed Bandit Problem</a>&#xFF09;&#xFF0C;&#x7136;&#x540E;&#x57FA;&#x4E8E;&#x6B64;&#xFF0C;&#x4ECB;&#x7ECD;Alpha Go&#x7684;&#x53E6;&#x4E00;&#x9879;&#x6838;&#x5FC3;&#x6280;&#x672F;&#xFF0C;&#x5373; <code>&#x8499;&#x7279;&#x5361;&#x6D1B;&#x6811;&#x641C;&#x7D22;</code> &#xFF08;<a href="https://en.wikipedia.org/wiki/Monte_Carlo_tree_search">Monte Carlo Tree Search</a>&#xFF09;&#xFF0C;&#x6700;&#x540E;&#x4F1A;&#x7B80;&#x8981;&#x4ECB;&#x7ECD;&#x6211;&#x7684;&#x7814;&#x7A76;&#x65B9;&#x5411; <code>&#x4EFF;&#x771F;&#x4F18;&#x5316;</code> &#xFF08;<a href="https://en.wikipedia.org/wiki/Simulation-based_optimization">Simulation Optimization</a>&#xFF09;&#x540C;&#x8FD9;&#x4E9B;&#x9886;&#x57DF;&#x7684;&#x5173;&#x7CFB;&#x3002;</b>
</p>
          <!-- only display read_more button if there's more to display -->
	  <a type="button" href="/2016/12/24/drl-from_mab_to_mcts/#more" class="btn btn-default more">进去看看</a>
	
  </div>
</div>
		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> Dec 18 2016 </div>
			<div class="article-title"><a href="/2016/12/18/drl-general_ai-intro/" title="深度增强学习的基本介绍以及对实现通用人工智能的探讨">深度增强学习【1】走向通用人工智能之路</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
           
  	      <div class="thumbnail"><a href="/2016/12/18/drl-general_ai-intro/"><img src="/2016/12/18/drl-general_ai-intro/DQNBreaker_Atari.jpg" alt="深度增强学习【1】走向通用人工智能之路"  class="nofancybox"></a>
           
		</div>
	
        
          <p>
&#x73B0;&#x5728;&#x4F46;&#x51E1;&#x5199;&#x4EBA;&#x5DE5;&#x667A;&#x80FD;&#x7684;&#x6587;&#x7AE0;&#xFF0C;&#x5FC5;&#x63D0;<a href="https://deepmind.com/research/alphago/">Alpha Go</a>&#x3002;&#x4E5F;&#x6B63;&#x662F;&#x56E0;&#x4E3A;Alpha Go&#x5728;&#x56F4;&#x68CB;&#x4EBA;&#x673A;&#x5927;&#x6218;&#x4E2D;&#x91CC;&#x7A0B;&#x7891;&#x5F0F;&#x7684;&#x80DC;&#x5229;&#xFF0C;&#x4EBA;&#x5DE5;&#x667A;&#x80FD;&#x8FCE;&#x6765;&#x4E86;&#x65B0;&#x7684;&#x6625;&#x5929;&#x3002; <b>&#x672C;&#x6587;&#x4E5F;&#x4E0D;&#x514D;&#x4FD7;&#x5957;&#xFF0C;&#x4ECE;Alpha Go&#x8BF4;&#x8D77;&#xFF0C;&#x4F46;&#x5E0C;&#x671B;&#x80FD;&#x6307;&#x660E;&#x4E00;&#x4E9B;&#x88AB;&#x5FFD;&#x89C6;&#x7684;&#x4F46;&#x5BF9;Alpha Go&#x68CB;&#x529B;&#x6709;&#x6DF1;&#x8FDC;&#x5F71;&#x54CD;&#x7684;&#x6280;&#x672F;&#x3002;</b> &#x56F4;&#x68CB;&#x4EBA;&#x5DE5;&#x667A;&#x80FD;&#x5927;&#x81F4;&#x53EF;&#x4EE5;&#x5206;&#x4E3A;&#x4E09;&#x4E2A;&#x9636;&#x6BB5;<sup><a id="fnr.1" name="fnr.1" class="footref" href="#fn.1">1</a></sup> &#xFF1A;&#x7B2C;&#x4E00;&#x9636;&#x6BB5;&#x4EE5;&#x542F;&#x53D1;&#x5F0F;&#x7B97;&#x6CD5;&#x4E3A;&#x4E3B;&#xFF0C;&#x6C34;&#x5E73;&#x4F4E;&#x4E8E;&#x4E1A;&#x4F59;&#x521D;&#x6BB5;&#xFF0C;&#x4EE3;&#x8868;&#x8F6F;&#x4EF6;&#x5373;&#x4EE5;&#x9759;&#x6001;&#x52BF;&#x529B;&#x51FD;&#x6570;&#x4E3A;&#x5F3A;&#x9879;&#x7684;<a href="https://zh.wikipedia.org/wiki/%E9%99%88%E5%BF%97%E8%A1%8C">&#x624B;&#x8C08;</a>&#xFF1B; &#x7B2C;&#x4E8C;&#x9636;&#x6BB5;&#x4EE5;<a href="https://zh.wikipedia.org/zh-sg/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%A0%91%E6%90%9C%E7%B4%A2">&#x8499;&#x7279;&#x5361;&#x6D1B;&#x6811;&#x641C;&#x7D22;&#x7B97;&#x6CD5; </a>&#x4E3A;&#x4EE3;&#x8868;&#xFF0C;&#x6C34;&#x5E73;&#x6700;&#x9AD8;&#x8FBE;&#x5230;&#x4E1A;&#x4F59;5&#x6BB5;&#xFF0C;&#x6BD4;&#x5982;&#x8BF4; <a href="http://senseis.xmp.net/?ZenGoProgram">Zen</a> &#xFF0C;<a href="https://www.remi-coulom.fr/CrazyStone/">Crazy Stone</a> &#xFF1B;&#x7B2C;&#x4E09;&#x9636;&#x6BB5;&#x4EE5; <code>&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;</code> &#xFF08;<a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a>&#xFF09;&#x4EE5;&#x53CA; <code>&#x589E;&#x5F3A;&#x5B66;&#x4E60;</code> &#xFF08;<a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement Learning</a>&#xFF0C;&#x4E5F;&#x79F0;&#x5F3A;&#x5316;&#x5B66;&#x4E60;&#xFF09;&#x7B97;&#x6CD5;&#x4E3A;&#x7A81;&#x7834;&#xFF0C;&#x5E76;&#x6218;&#x80DC;&#x4E86;&#x4EBA;&#x7C7B;&#x804C;&#x4E1A;&#x4E5D;&#x6BB5;&#x68CB;&#x624B;&#x674E;&#x4E16;&#x4E6D;&#xFF0C;&#x8FD9;&#x4E5F;&#x5C31;&#x662F;Alpha Go&#x7684;&#x6545;&#x4E8B;&#x4E86;&#x3002;&#x6BCF;&#x6BCF;&#x63D0;&#x5230;Alpha Go&#x5353;&#x8D8A;&#x7684;&#x80FD;&#x529B;&#xFF0C;&#x5F80;&#x5F80;&#x5F52;&#x548E;&#x4E8E;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x7684;&#x5F3A;&#x5927;&#xFF0C;&#x4F46;&#x5B9E;&#x9645;&#x4E0A;&#x589E;&#x5F3A;&#x5B66;&#x4E60;&#x7B97;&#x6CD5;&#x4E5F;&#x529F;&#x4E0D;&#x53EF;&#x6CA1;&#x3002;&#x8FD9;&#x4E8C;&#x8005;&#x7684;&#x7ED3;&#x5408;&#x88AB;&#x79F0;&#x4E4B;&#x4E3A; <code>&#x6DF1;&#x5EA6;&#x589E;&#x5F3A;&#x5B66;&#x4E60;</code> &#xFF08;<a href="https://deepmind.com/blog/deep-reinforcement-learning/">Deep Reinforcement Learning</a>&#xFF0C;DRL&#xFF09;&#xFF0C;&#x6700;&#x521D;&#x89C1;&#x4E8E;DeepMind&#x5728;Nature&#x4E0A;&#x53D1;&#x8868;&#x7684;<a href="http://www.nature.com/nature/journal/v518/n7540/abs/nature14236.html">Human-level control through deep reinforcement learning</a>&#x3002; <b>&#x672C;&#x6587;&#x8BD5;&#x56FE;&#x4ECE;&#x6DF1;&#x5EA6;&#x589E;&#x5F3A;&#x5B66;&#x4E60;&#x7684;&#x89D2;&#x5EA6;&#x6765;&#x63A2;&#x8BA8;&#x901A;&#x7528;&#x4EBA;&#x5DE5;&#x667A;&#x80FD;&#x7684;&#x5B9E;&#x73B0;&#xFF0C;&#x5E76;&#x7B80;&#x8981;&#x4ECB;&#x7ECD;&#x4E86;&#x6DF1;&#x5EA6;&#x589E;&#x5F3A;&#x5B66;&#x4E60;&#x7684;&#x57FA;&#x7840;&#x77E5;&#x8BC6;&#x3001;&#x5E38;&#x89C1;&#x7B97;&#x6CD5;&#x4EE5;&#x53CA;&#x76F8;&#x5173;&#x5E94;&#x7528;&#x3002;</b>
</p>
          <!-- only display read_more button if there's more to display -->
	  <a type="button" href="/2016/12/18/drl-general_ai-intro/#more" class="btn btn-default more">进去看看</a>
	
  </div>
</div>
		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> Dec 4 2016 </div>
			<div class="article-title"><a href="/2016/12/04/my_liqi/" title="本文约3000字，需4~6分钟读完。本文参加了『利器社群计划』，着重推荐了本人重度使用的工具库以及多年来总结出的工作流。">工欲善其事，必先利其器</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
           
  	      <div class="thumbnail"><a href="/2016/12/04/my_liqi/"><img src="/2016/12/04/my_liqi/jellyfish.png" alt="工欲善其事，必先利其器"  class="nofancybox"></a>
           
		</div>
	
        
          <p>
&#x672C;&#x6587;&#x53C2;&#x4E0E;&#x4E86;&#x300C;&#x5229;&#x5668;&#x793E;&#x7FA4;&#x8BA1;&#x5212;&#x300D;&#xFF0C;&#x53D1;&#x73B0;&#x66F4;&#x591A;&#x521B;&#x9020;&#x8005;&#x548C;&#x4ED6;&#x4EEC;&#x7684;&#x5DE5;&#x5177;&#xFF1A;<a href="http://liqi.io/community/">http://liqi.io/community/</a> &#xFF0C;&#x7740;&#x91CD;&#x63A8;&#x8350;&#x4E86;&#x672C;&#x4EBA;&#x91CD;&#x5EA6;&#x4F7F;&#x7528;&#x7684;&#x5DE5;&#x5177;&#x5E93;&#x4EE5;&#x53CA;&#x591A;&#x5E74;&#x6765;&#x603B;&#x7ED3;&#x51FA;&#x7684;&#x5DE5;&#x4F5C;&#x6D41;&#x3002;&#x9664;&#x6B64;&#x4E4B;&#x5916;&#xFF0C;&#x4E5F;&#x63A2;&#x8BA8;&#x4E86;&#x6211;&#x7684;&#x804C;&#x4E1A;&#x751F;&#x6DAF;&#x8F6C;&#x6298;&#x70B9;&#x3001;&#x6700;&#x7406;&#x60F3;&#x7684;&#x5DE5;&#x4F5C;&#x73AF;&#x5883;&#x4EE5;&#x53CA;&#x5E73;&#x65F6;&#x83B7;&#x5F97;&#x5DE5;&#x4F5C;&#x7075;&#x611F;&#x7684;&#x4E00;&#x4E9B;&#x65B9;&#x5F0F;&#x3002;
</p>
          <!-- only display read_more button if there's more to display -->
	  <a type="button" href="/2016/12/04/my_liqi/#more" class="btn btn-default more">进去看看</a>
	
  </div>
</div>
		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> Mar 12 2016 </div>
			<div class="article-title"><a href="/2016/03/12/CF-598D/" title="Codeforces - 598D Igor In the Museum 解题报告，带记忆的深度优先搜索">Codeforces - 598D Igor In the Museum</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
           
  	      <div class="thumbnail"><a href="/2016/03/12/CF-598D/"><img src="/2016/03/12/CF-598D/codeforces-logo.png" alt="Codeforces - 598D Igor In the Museum"  class="nofancybox"></a>
           
		</div>
	
        
          <p>
<a href="http://blog.greenwicher.com/2016/02/15/CF-598C/">&#x524D;&#x6587;</a>&#x66FE;&#x63D0;&#x5230;&#x8FC7;&#x89E3;&#x51B3;&#x4E00;&#x4E2A;&#x7B97;&#x6CD5;&#x95EE;&#x9898;&#xFF0C;&#x5927;&#x6982;&#x53EF;&#x4EE5;&#x5212;&#x5206;&#x4E3A;&#x4E09;&#x4E2A;&#x9636;&#x6BB5;&#x3002;&#x7B2C;&#x4E00;&#x9636;&#x6BB5;&#x662F;&#x7B97;&#x6CD5;&#x8BBE;&#x8BA1;&#xFF0C;&#x5373;&#x4EBA;&#x8111;&#x51C6;&#x786E;&#x65E0;&#x8BEF;&#x7406;&#x89E3;&#x7B97;&#x6CD5;&#x95EE;&#x9898;&#xFF0C;&#x5E76;&#x8BBE;&#x8BA1;&#x7B97;&#x6CD5;&#xFF0C;&#x8FD9;&#x4E00;&#x9636;&#x6BB5;&#x5C5E;&#x4E8E;&#x6A21;&#x578B;&#x5728;&#x601D;&#x7EF4;&#x4E0A;&#x7684;&#x6784;&#x5EFA;&#x3002;&#x7B2C;&#x4E8C;&#x9636;&#x6BB5;&#x662F;&#x7B97;&#x6CD5;&#x5B9E;&#x65BD;&#xFF0C;&#x5373;&#x7A0B;&#x5E8F;&#x5458;&#x7528;&#x81EA;&#x5DF1;&#x949F;&#x7231;&#x7684;&#x8BED;&#x8A00;&#x5BF9;&#x601D;&#x7EF4;&#x4E0A;&#x7684;&#x6A21;&#x578B;&#x8FDB;&#x884C;&#x73B0;&#x5B9E;&#x5316;&#xFF0C;&#x4F9D;&#x9760;&#x8BA1;&#x7B97;&#x673A;&#x6765;&#x83B7;&#x5F97;&#x7ED3;&#x679C;&#xFF0C;&#x8FD9;&#x4E00;&#x9636;&#x6BB5;&#x5C5E;&#x4E8E;&#x6A21;&#x578B;&#x5728;&#x4EE3;&#x7801;&#x4E0A;&#x7684;&#x6784;&#x5EFA;&#x3002;&#x6700;&#x540E;&#x4E00;&#x9636;&#x6BB5;&#xFF0C;&#x5373;&#x8BA1;&#x7B97;&#x673A;&#x6267;&#x884C;&#x7A0B;&#x5E8F;&#x5458;&#x7ED9;&#x5B9A;&#x7684;&#x547D;&#x4EE4;&#xFF0C;&#x5E76;&#x8FD4;&#x56DE;&#x5176;&#x6240;&#x5E0C;&#x671B;&#x7684;&#x7ED3;&#x679C;&#xFF0C;&#x8FD9;&#x4E00;&#x9636;&#x6BB5;&#x5C5E;&#x4E8E;&#x6A21;&#x578B;&#x5728;&#x8BA1;&#x7B97;&#x673A;&#x786C;&#x4EF6;&#x4E0A;&#x7684;&#x6784;&#x5EFA;&#x3002;&#x4E3A;&#x4E86;&#x4FDD;&#x8BC1;&#x6700;&#x7EC8;&#x8F93;&#x51FA;&#x7684;&#x6B63;&#x786E;&#x6027;&#xFF0C;&#x8FD9;&#x4E09;&#x4E2A;&#x9636;&#x6BB5;&#x4E0D;&#x80FD;&#x53D1;&#x751F;&#x4EFB;&#x4F55;&#x53EF;&#x9884;&#x89C1;&#x6216;&#x8005;&#x610F;&#x60F3;&#x4E0D;&#x5230;&#x7684;&#x9519;&#x8BEF;&#x3002;&#x7B97;&#x6CD5;&#x8FD0;&#x884C;&#x4E2D;&#x7684;&#x7CBE;&#x5EA6;&#x95EE;&#x9898;&#x5728;<a href="http://blog.greenwicher.com/2016/02/15/CF-598C/">&#x524D;&#x6587;</a>&#x4E2D;&#x5DF2;&#x6709;&#x6240;&#x63CF;&#x8FF0;&#xFF0C;&#x8FD9;&#x4E00;&#x6B21;&#x6211;&#x4EEC;&#x6765;&#x8C08;&#x8C08;&#x7B97;&#x6CD5;&#x5B9E;&#x65BD;&#x9636;&#x6BB5;&#xFF0C;&#x5E76;&#x4EE5;<a href="http://codeforces.com/contest/598/problem/D">Codeforces 598D</a>&#x6765;&#x8BF4;&#x660E;&#x5982;&#x4F55;&#x5199;&#x66F4;&#x7CBE;&#x7B80;&#x7684;&#x4EE3;&#x7801;&#x3002;
</p>
          <!-- only display read_more button if there's more to display -->
	  <a type="button" href="/2016/03/12/CF-598D/#more" class="btn btn-default more">进去看看</a>
	
  </div>
</div>
		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> Feb 15 2016 </div>
			<div class="article-title"><a href="/2016/02/15/部署个性化子域名网站到Github/" title="本文介绍了如何利用Github Pages来部署个性化子域名站点">部署个性化子域名网站到Github</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
           
  	      <div class="thumbnail"><a href="/2016/02/15/部署个性化子域名网站到Github/"><img src="/2016/02/15/部署个性化子域名网站到Github/Your-Personal-Domain.png" alt="部署个性化子域名网站到Github"  class="nofancybox"></a>
           
		</div>
	
        
          <p>
&#x6700;&#x8FD1;&#x51E0;&#x5E74;&#xFF0C;&#x8D8A;&#x6765;&#x8D8A;&#x591A;&#x7684;&#x4EBA;&#x57FA;&#x4E8E;Jekyll&#xFF0C;Octopress&#x6216;&#x8005;Hexo&#x7B49;&#x6E32;&#x67D3;&#x6846;&#x67B6;&#x5728;Github&#x4E0A;&#x5EFA;&#x7ACB;&#x4E86;&#x81EA;&#x5DF1;&#x7684;&#x9759;&#x6001;&#x535A;&#x5BA2;&#x3002;&#x6709;&#x4E86;&#x8FD9;&#x4E9B;&#x6E32;&#x67D3;&#x6846;&#x67B6;&#x540E;&#xFF0C;&#x4F60;&#x53EA;&#x8981;&#x77E5;&#x9053;&#x6700;&#x57FA;&#x672C;&#x7684; <code>markdown</code> &#x8BED;&#x6CD5;&#xFF08;&#x5BF9;&#x4E8E;Emacs&#x7528;&#x6237;&#xFF0C;&#x4F1A;&#x7528; <code>org mode</code> &#xFF09;&#xFF0C;&#x9009;&#x62E9;&#x4E00;&#x4E2A;&#x81EA;&#x5DF1;&#x559C;&#x6B22;&#x7684;&#x7F51;&#x7AD9;&#x4E3B;&#x9898;&#xFF0C;&#x7136;&#x540E;&#x5176;&#x4ED6;&#x4E8B;&#x60C5;&#x57FA;&#x672C;&#x5C31;&#x4E0D;&#x9700;&#x8981;&#x5173;&#x5FC3;&#x4E86;&#x3002;&#x8FD9;&#x6837;&#x7684;&#x597D;&#x5904;&#x662F;&#xFF0C;&#x5199;&#x4F5C;&#x8005;&#x80FD;&#x66F4;&#x52A0;&#x4E13;&#x5FC3;&#x4E8E;&#x5199;&#x4F5C;&#x5185;&#x5BB9;&#xFF0C;&#x540C;&#x65F6;&#x66F4;&#x52A0;&#x65B9;&#x4FBF;&#x7684;&#x628A;&#x81EA;&#x5DF1;&#x7684;&#x601D;&#x60F3;&#x89C1;&#x89E3;&#x7ECF;&#x9A8C;&#x5728;&#x4E92;&#x8054;&#x7F51;&#x4E0A;&#x5171;&#x4EAB;&#x51FA;&#x6765;&#x3002;&#x5173;&#x4E8E;&#x5982;&#x4F55;&#x5229;&#x7528;&#x4EE5;&#x4E0A;&#x6280;&#x672F;&#x5728;Github&#x6216;&#x8005;Gitcafe&#x4E0A;&#x5EFA;&#x7ACB;&#x4E2A;&#x4EBA;&#x535A;&#x5BA2;&#x7684;&#x6587;&#x7AE0;&#x51E0;&#x4E4E;&#x5DF2;&#x7ECF;&#x6F2B;&#x5929;&#x98DE;&#x4E86;&#xFF0C;&#x4F46;&#x662F;&#x6709;&#x7684;&#x65F6;&#x5019;&#x6211;&#x4EEC;&#x66F4;&#x5E0C;&#x671B;&#x62E5;&#x6709;&#x4E00;&#x4E2A;&#x5168;&#x9762;&#x7684;&#x7F51;&#x7AD9;&#xFF0C;&#x8FD9;&#x4E2A;&#x7F51;&#x7AD9;&#x53EF;&#x4EE5;&#x5305;&#x542B;&#x6211;&#x4EEC;&#x7684;&#x7EF4;&#x57FA;&#x5B50;&#x7AD9;&#x70B9;&#x6216;&#x8005;&#x9879;&#x76EE;&#x5B50;&#x7AD9;&#x70B9;&#x3002;&#x4F46;&#x662F;&#x76EE;&#x524D;&#x7684;&#x6587;&#x7AE0;&#x4EE5;&#x53CA;&#x6E32;&#x67D3;&#x6280;&#x672F;&#x4E3B;&#x8981;&#x90FD;&#x662F;&#x9488;&#x5BF9;&#x4E2A;&#x4EBA;&#x535A;&#x5BA2;&#x7684;&#x5EFA;&#x8BBE;&#xFF0C;&#x672C;&#x6587;&#x8BD5;&#x56FE;&#x5F25;&#x8865;&#x8FD9;&#x4E2A;&#x7A7A;&#x7F3A;&#xFF0C;&#x63D0;&#x51FA;&#x5229;&#x7528;Github Pages&#x6765;&#x90E8;&#x7F72;&#x4E2A;&#x6027;&#x5316;&#x5B50;&#x57DF;&#x540D;&#x7AD9;&#x70B9;&#x7684;&#x65B9;&#x6CD5;&#x3002;&#x8BFB;&#x5B8C;&#x672C;&#x6587;&#xFF0C;&#x4F60;&#x5C31;&#x53EF;&#x4EE5;&#x521B;&#x5EFA;&#x8BF8;&#x5982; <code>wiki.greenwicher.com</code> &#x6216;&#x8005; <code>love.greenwicher.com</code> &#x8FD9;&#x7C7B;&#x7684;&#x5B50;&#x7AD9;&#x70B9;&#x4E86;&#x3002;
</p>
          <!-- only display read_more button if there's more to display -->
	  <a type="button" href="/2016/02/15/部署个性化子域名网站到Github/#more" class="btn btn-default more">进去看看</a>
	
  </div>
</div>
		
			
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> Feb 15 2016 </div>
			<div class="article-title"><a href="/2016/02/15/CF-598C/" title="Codeforces - 598C Nearest Vectors 解题报告，高精度问题">Codeforces - 598C Nearest vectors</a></div>						
		</h3>
	


			<div class="entry">
  <div class="row">
	
           
  	      <div class="thumbnail"><a href="/2016/02/15/CF-598C/"><img src="/2016/02/15/CF-598C/codeforces-logo.png" alt="Codeforces - 598C Nearest vectors"  class="nofancybox"></a>
           
		</div>
	
        
          <p>
&#x4ECE;&#x7CFB;&#x7EDF;&#x7684;&#x89D2;&#x5EA6;&#x6765;&#x770B;&#xFF0C;&#x7ED9;&#x5B9A;&#x4E00;&#x4E2A;&#x7B97;&#x6CD5;&#x95EE;&#x9898;&#x548C;&#x8F93;&#x5165;&#xFF0C;&#x8981;&#x4F7F;&#x5F97;&#x8BA1;&#x7B97;&#x673A;&#x8F93;&#x51FA;&#x6B63;&#x786E;&#x7684;&#x7ED3;&#x679C;&#xFF0C;&#x90A3;&#x4E48;&#x5FC5;&#x987B;&#x4FDD;&#x8BC1;&#x81F3;&#x5C11;&#x4E0B;&#x9762;&#x4E09;&#x4E2A;&#x73AF;&#x8282;&#x662F;&#x6B63;&#x786E;&#x65E0;&#x8BEF;&#x7684;&#x3002;
</p>
<ul class="org-ul">
<li>&#x7B97;&#x6CD5;&#x8BBE;&#x8BA1; &#xFF08;&#x601D;&#x7EF4;&#x4E0A;&#x7684;&#x6784;&#x5EFA;&#xFF09;
</li>
<li>&#x7B97;&#x6CD5;&#x5B9E;&#x65BD; &#xFF08;&#x4EE3;&#x7801;&#x4E0A;&#x7684;&#x6784;&#x5EFA;&#xFF09;
</li>
<li>&#x7B97;&#x6CD5;&#x8FD0;&#x884C; &#xFF08;&#x8BA1;&#x7B97;&#x673A;&#x786C;&#x4EF6;&#x4E0A;&#x7684;&#x6784;&#x5EFA;&#xFF09;
</li>
</ul>
<p>
&#x8FD9;&#x5176;&#x4E2D;&#x7684;&#x4EFB;&#x4E00;&#x73AF;&#x8282;&#x51FA;&#x73B0;&#x4E86;&#x9519;&#x8BEF;&#xFF0C;&#x90FD;&#x65E0;&#x6CD5;&#x4FDD;&#x8BC1;&#x6700;&#x7EC8;&#x7684;&#x6B63;&#x786E;&#x7ED3;&#x679C;&#x3002;&#x524D;&#x4E24;&#x4E2A;&#x73AF;&#x8282;&#x4E3B;&#x8981;&#x53D6;&#x51B3;&#x4E8E;&#x4EBA;&#x7684;&#x80FD;&#x529B;&#xFF08;&#x7406;&#x89E3;&#x95EE;&#x9898;&#xFF0C;&#x89E3;&#x51B3;&#x95EE;&#x9898;&#xFF09;&#x4E0E;&#x7EC6;&#x5FC3;&#x7A0B;&#x5EA6;&#xFF0C;&#x800C;&#x6700;&#x540E;&#x4E00;&#x4E2A;&#x73AF;&#x8282;&#x91CD;&#x70B9;&#x5728;&#x4E8E;&#x4EBA;&#x5BF9;&#x8BA1;&#x7B97;&#x673A;&#x7684;&#x5E95;&#x5C42;&#x7406;&#x89E3;&#x3002;&#x6362;&#x53E5;&#x8BDD;&#x8BF4;&#xFF0C;&#x5373;&#x4F7F;&#x95EE;&#x9898;&#x5728;&#x6211;&#x4EEC;&#x7684;&#x8111;&#x6D77;&#x4E2D;&#x5DF2;&#x88AB;&#x5B8C;&#x7F8E;&#x89E3;&#x51B3;&#xFF0C;&#x4F46;&#x5728;&#x7B97;&#x6CD5;&#x8FD0;&#x884C;&#x65F6;&#xFF0C;&#x8BA1;&#x7B97;&#x673A;&#x5BF9;&#x8BE5;&#x95EE;&#x9898;&#x7684;&#x91CD;&#x65B0;&#x8868;&#x8FBE;&#x53EF;&#x80FD;&#x4F1A;&#x51FA;&#x73B0;&#x504F;&#x5DEE;&#x3002;&#x6700;&#x5E38;&#x89C1;&#x7684;&#x504F;&#x5DEE;&#x5C31;&#x662F;&#x8BA1;&#x7B97;&#x673A;&#x7CBE;&#x5EA6;&#x95EE;&#x9898;&#xFF0C;&#x6BD5;&#x7ADF;&#x662F;&#x4EE5;&#x79BB;&#x6563;&#x6765;&#x903C;&#x8FD1;&#x8FDE;&#x7EED;&#xFF0C;&#x51FA;&#x73B0;&#x300E;&#x7CBE;&#x786E;&#x7684;&#x9519;&#x8BEF;&#x300F;&#x662F;&#x5728;&#x6240;&#x96BE;&#x514D;&#x7684;&#x3002;&#x4F46;&#x5F53;&#x6B63;&#x786E;&#x6027;&#x548C;&#x9AD8;&#x7CBE;&#x5EA6;&#x53EA;&#x80FD;&#x4E8C;&#x9009;&#x4E00;&#x65F6;&#xFF0C;&#x663E;&#x7136;&#x6CA1;&#x6709;&#x4EBA;&#x4F1A;&#x56E0;&#x4E3A;&#x9AD8;&#x7CBE;&#x5EA6;&#x800C;&#x8FFD;&#x6C42;&#x7CBE;&#x786E;&#x7684;&#x9519;&#x8BEF;&#x3002;&#x8FD9;&#x7BC7;&#x6587;&#x7AE0;&#x5C31;&#x4EE5;<a href="http://codeforces.com/contest/598/problem/C#">Codeforces 598C</a>&#x8FD9;&#x9053;&#x9898;&#x6765;&#x63A2;&#x8BA8;&#x7B2C;&#x4E09;&#x4E2A;&#x73AF;&#x8282;&#x7B97;&#x6CD5;&#x8FD0;&#x884C;&#x4E2D;&#x7684;&#x7CBE;&#x5EA6;&#x95EE;&#x9898;&#x3002;&#x8FD9;&#x9053;&#x9898;&#x76EE;&#x672C;&#x8EAB;&#x5E76;&#x4E0D;&#x96BE;&#xFF0C;&#x4F46;&#x5728;&#x6B63;&#x5F0F;&#x6BD4;&#x8D5B;&#x4E2D;&#x53EA;&#x6709;57&#x4E2A;&#x4EBA;AC&#xFF0C;&#x4EC5;&#x4F4E;&#x4E8E;F&#x9898;&#x3002;&#x8BF4;&#x5176;&#x4E0D;&#x96BE;&#xFF0C;&#x662F;&#x56E0;&#x4E3A;&#x7B97;&#x6CD5;&#x8BBE;&#x8BA1;&#x4EE5;&#x53CA;&#x7B97;&#x6CD5;&#x5B9E;&#x65BD;&#x73AF;&#x8282;&#x592A;&#x663E;&#x800C;&#x6613;&#x89C1;&#x4E86;&#xFF0C;&#x4F46;&#x8FD9;&#x4E48;&#x4F4E;&#x7684;AC&#x7387;&#x5C31;&#x662F;&#x56E0;&#x4E3A;&#x5927;&#x591A;&#x6570;&#x4EBA;&#x5728;&#x8FD9;&#x9053;&#x9898;&#x7CBE;&#x5EA6;&#x4E0A;&#x51FA;&#x4E86;&#x95EE;&#x9898;&#x3002;
</p>
          <!-- only display read_more button if there's more to display -->
	  <a type="button" href="/2016/02/15/CF-598C/#more" class="btn btn-default more">进去看看</a>
	
  </div>
</div>
		

		</div>

		<!-- pagination -->
		<div>
  		<center>
		<div class="pagination">
<ul class="pagination">
	 
		
          <li class="prev disabled"><a><i class="fa fa-arrow-circle-o-left"></i>上一页</a></li>
        

        <li><a href="/"><i class="fa fa-home"></i>首页</a></li>

		
		   <li class="next"> <a href="/page/2/" class="alignright next">下一页<i class="fa fa-arrow-circle-o-right"></i></a> </li>          
        
	
</ul>
</div>

  		</center>
		</div>

		
		
	</div> <!-- col-md-9 -->

	
		<div class="col-md-3">
	<div id="sidebar">
	
			<!--subscriber-->

<!-- Begin MailChimp Signup Form -->
<link href="//cdn-images.mailchimp.com/embedcode/classic-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
        #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }
        /* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
           We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
</style>
<div id="mc_embed_signup">
<form action="//greenwicher.us14.list-manage.com/subscribe/post?u=8da47f8ec088ffc8c8d5b6b88&amp;id=d8da6d2b40" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
        <h4>Greenwicher's Newsletter</h4>
<div class="mc-field-group">
        <input type="email" value="" name="EMAIL" placeholder="输入您的邮箱，即可一键订阅" class="required email" id="mce-EMAIL">
</div>
        <div id="mce-responses" class="clear">
                <div class="response" id="mce-error-response" style="display:none"></div>
                <div class="response" id="mce-success-response" style="display:none"></div>
        </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_8da47f8ec088ffc8c8d5b6b88_d8da6d2b40" tabindex="-1" value=""></div>
    <div class="clear"><input type="submit" value="订阅" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

<!--End mc_embed_signup-->
<!--end of subscriber-->
<hr>
		
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="搜索" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>

<hr>

		
			
	<div class="widget">
		<h4>分类</h4>
		<ul class="tag_box inline list-unstyled">
		
			<li><a href="/categories/如何做投资/">如何做投资<span>2</span></a></li>
		
			<li><a href="/categories/如何做科研/">如何做科研<span>1</span></a></li>
		
			<li><a href="/categories/如何写算法/">如何写算法<span>3</span></a></li>
		
			<li><a href="/categories/如何创造AI/">如何创造AI<span>2</span></a></li>
		
			<li><a href="/categories/杂/">杂<span>2</span></a></li>
		
			<li><a href="/categories/测试/">测试<span>1</span></a></li>
		
			<li><a href="/categories/随笔/">随笔<span>2</span></a></li>
		
		</ul>
	</div>

		
			
	<div class="widget">
		<h4>标签云</h4>
		<ul class="tag_box inline list-unstyled">		
		
			<li><a href="/tags/人工智能/">人工智能<span>2</span></a></li>
		
			<li><a href="/tags/书评/">书评<span>2</span></a></li>
		
			<li><a href="/tags/生活/">生活<span>1</span></a></li>
		
			<li><a href="/tags/网站开发/">网站开发<span>1</span></a></li>
		
			<li><a href="/tags/工作流/">工作流<span>1</span></a></li>
		
			<li><a href="/tags/记录/">记录<span>1</span></a></li>
		
			<li><a href="/tags/推荐/">推荐<span>1</span></a></li>
		
			<li><a href="/tags/算法实施/">算法实施<span>1</span></a></li>
		
			<li><a href="/tags/深度优先搜索/">深度优先搜索<span>1</span></a></li>
		
			<li><a href="/tags/投资/">投资<span>2</span></a></li>
		
			<li><a href="/tags/高精度/">高精度<span>1</span></a></li>
		
			<li><a href="/tags/Github/">Github<span>1</span></a></li>
		
			<li><a href="/tags/深度学习/">深度学习<span>1</span></a></li>
		
			<li><a href="/tags/仿真优化/">仿真优化<span>1</span></a></li>
		
			<li><a href="/tags/指南/">指南<span>1</span></a></li>
		
			<li><a href="/tags/规划/">规划<span>1</span></a></li>
		
			<li><a href="/tags/codeforces/">codeforces<span>3</span></a></li>
		
			<li><a href="/tags/工具库/">工具库<span>1</span></a></li>
		
			<li><a href="/tags/增强学习/">增强学习<span>2</span></a></li>
		
			<li><a href="/tags/开源项目/">开源项目<span>1</span></a></li>
		
		
		   <li><a href="/tags">...<span>34</span></a></li>
		 
		</ul>
	</div>


		
			
<div class="widget">
  <h4>最新文章</h4>
  <ul class="entry list-unstyled">
    
      <li>
        <a href="/2017/01/09/drl-general_ai-intro-test/"  title="邮件订阅测试" ><i class="fa fa-file-o"></i>邮件订阅测试...</a>
      </li>
    
      <li>
        <a href="/2017/01/03/codeforces-problemset/"  title="简要介绍如何科学地刷算法题，来提高自己解决问题的能力，并利用爬虫抓取Codeforces的题库，来分析题目难度以及算法分类的关系" ><i class="fa fa-file-o"></i>Codeforces科学刷题指南，一图一表便够了...</a>
      </li>
    
      <li>
        <a href="/2017/01/01/hello-2017/"  title="我的2017年规划" ><i class="fa fa-file-o"></i>Hello 2017...</a>
      </li>
    
      <li>
        <a href="/2016/12/31/good-bye-2016/"  title="我的2016年总结" ><i class="fa fa-file-o"></i>Good Bye 2016...</a>
      </li>
    
      <li>
        <a href="/2016/12/24/drl-from_mab_to_mcts/"  title="两个重要的增强学习问题：多臂赌博机问题和蒙特卡洛树搜索" ><i class="fa fa-file-o"></i>深度增强学习【2】从多臂赌博机问题到蒙特卡洛树搜索...</a>
      </li>
    
  </ul>
</div>


		
			
<div class="widget">
	<h4>个人链接</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="https://github.com/Greenwicher" title="Greenwicher's Github repository." target="_blank"]);">My Github</a></li>
	
		<li><i class="fa fa-linkedin"></i><a href="https://www.linkedin.com/in/weizhiliu" title="My Linkin account." target="_blank"]);">My LinkedIn</a></li>
	
		<li><i class="fa fa-book"></i><a href="http://www.douban.com/people/Greenwicher/" title="My Douban account." target="_blank"]);">My Douban</a></li>
	
	</ul>
</div>


		
			
<div class="widget">
        <h4>友情链接</h4>
        <ul class="blogroll list-unstyled">
        
                <li><i class="fa fa-user"></i><a href="http://norvig.com/" title="Peter Norvig的博客" target="_blank"]);">Peter Norvig</a></li>
        
                <li><i class="fa fa-user"></i><a href="http://www.yangzhiping.com/" title="阳志平的网志" target="_blank"]);">阳志平的网志</a></li>
        
                <li><i class="fa fa-user"></i><a href="http://mindhacks.cn/" title="刘未鹏的博客" target="_blank"]);">刘未鹏 | Mind Hacks</a></li>
        
                <li><i class="fa fa-user"></i><a href="http://www.matrix67.com/blog/" title="Matrix67的博客" target="_blank"]);">Matrix67: The Aha Moments</a></li>
        
                <li><i class="fa fa-user"></i><a href="http://www.ruanyifeng.com/blog/" title="阮一峰的博客" target="_blank"]);">阮一峰的网络日志</a></li>
        
                <li><i class="fa fa-user"></i><a href="http://licstar.net/" title="LICSTAR的博客" target="_blank"]);">LICSTAR的博客</a></li>
        
                <li><i class="fa fa-user"></i><a href="http://freemind.pluskid.org/" title="pluskid的博客" target="_blank"]);">Free Mind</a></li>
        
        </ul>
</div>


		
			
<div class="widget">
        <h4>网站推荐</h4>
        <ul class="blogroll list-unstyled">
        
                <li><i class="fa fa-code"></i><a href="http://codeforces.com/" title="Codeforces is a Russian website dedicated to competitive programming. It was created and is maintained by a group of competitive programmers from Saratov State University led by Mikhail Mirzayanov. Since 2013, Codeforces has surpassed TopCoder in terms of active contestants." target="_blank"]);">Codeforces</a></li>
        
                <li><i class="fa fa-code"></i><a href="http://www.kaggle.com/" title="Kaggle是一个数据建模和数据分析竞赛平台。企业和研究者可在其上发布数据，统计学者和数据挖掘专家可在其上进行竞赛以产生最好的模型。这一众包模式依赖于这一事实，即有众多策略可以用于解决几乎所有预测建模的问题，而研究者不可能在一开始就了解什么方法对于特定问题是最为有效的。Kaggle的目标则是试图通过众包的形式来解决这一难题，进而使数据科学成为一场运动。" target="_blank"]);">Kaggle</a></li>
        
                <li><i class="fa fa-code"></i><a href="https://gym.openai.com/" title="A toolkit for developing and comparing reinforcement learning algorithms. It supports teaching agents everything from walking to playing games like Pong or Go." target="_blank"]);">OpenAI Gym</a></li>
        
                <li><i class="fa fa-line-chart"></i><a href="https://www.ricequant.com/" title="深圳米筐科技有限公司 的终极目标是成为每一个宽客 ( Quant ) 的私人量化交易平台。所有的灵感可以在我们这里变成代码，通过我们安全、极速的平台交易获得运算结果，每一个策略都可以通过我们的平台实现。不管你是量化交易员、宽客，是还在学校读书的学生、亦或是想一窥金融市场门径的工程师，不管你已经是沉浮市场多年的牛人，还是有志于此的新手，你们都是我们在寻找的人才。在 Ricequant 的平台上，你们无需担心海量的金融数据处理和复杂的量化模型运算，只需要把所有的才能都投注于策略的设计的优化。" target="_blank"]);">Ricequant</a></li>
        
                <li><i class="fa fa-line-chart"></i><a href="https://uqer.io/home/" title="『优矿』是您的私人的量化研究与交易云平台。我们旨在打破金融量化的壁垒，为广大量化爱好者提供华尔街专业量化机构的装备。优矿提供了高质量的海量金融数据与高性能的分析工具，与您共襄智慧与金融在大数据时代的红利。" target="_blank"]);">Uqer</a></li>
        
                <li><i class="fa fa-wrench"></i><a href="http://liqi.io/" title="利器采访优秀的创造者，邀请他们来分享工作时所使用的工具，以及使用工具的方式和原则。进而探索人与工具，人与科技之间的关系。在利器看来，工具可以是一个高效的软件或硬件，也可以是一本书或网站……但凡能辅助创造者完成创造的物件，都是「利器」。这样的工具将赋予更多个体力量，让个体创造出更多可能性。" target="_blank"]);">利器：创造者和他们的工具</a></li>
        
                <li><i class="fa fa-newspaper-o"></i><a href="https://the-offline.com/" title="《离线》是一本关于科技与文化的杂志，她为热爱思考与创新的人提供深度的阅读体验。" target="_blank"]);">OFFLINE | 离线周刊</a></li>
        
                <li><i class="fa fa-newspaper-o"></i><a href="http://www.jiqizhixin.com/" title="机器之心是国内领先的前沿科技垂直媒体，关注人工智能、机器人、神经认知科学等前沿科技以及深度科技思考，旨在通过高质量内容让用户更好地了解即将到来的下一次技术变革，同时启发大家对人与科技的哲学思考。" target="_blank"]);">机器之心</a></li>
        
                <li><i class="fa fa-newspaper-o"></i><a href="http://36kr.com/" title="36氪，专注互联网创业" target="_blank"]);">36氪</a></li>
        
                <li><i class="fa fa-newspaper-o"></i><a href="https://www.wired.com/" title="Wired is a monthly American magazine, published in print and online editions, that focuses on how emerging technologies affect culture, the economy, and politics." target="_blank"]);">Wired</a></li>
        
                <li><i class="fa fa-paper-plane"></i><a href="https://www.zhihu.com/" title="发现更大的世界" target="_blank"]);">知乎</a></li>
        
                <li><i class="fa fa-paper-plane"></i><a href="https://arxiv.org/" title="arXiv is an e-print service in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance and statistics." target="_blank"]);">arXiv.org</a></li>
        
                <li><i class="fa fa-paper-plane"></i><a href="http://www.gitxiv.com/" title="GitXiv is a space to share collaborative open computer science projects. Countless Github and arXiv links are floating around the web. Its hard to keep track of these gems. GitXiv attempts to solve this problem by offering a collaboratively curated feed of projects. Each project is conveniently presented as arXiv + Github + Links + Discussion. Members can submit their findings and let the community rank and discuss it. A regular newsletter makes it easy to stay up-to-date on recent advancements. It´s free and open." target="_blank"]);">GitXiv</a></li>
        
        </ul>
</div>

		
			<div class="widget tag">
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- 文末横幅 -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4230509553120128"
     data-ad-slot="1153059496"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
</div>

		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->

	
	
</div> <!-- row-fluid -->

	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2017 LIU Weizhi
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.
</br>
本站共迎来了<span id="busuanzi_value_site_uv"></span>个小伙伴，总计<span id="busuanzi_value_site_pv"></span>次站点流量.

</p>

<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
 </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
   </html>
